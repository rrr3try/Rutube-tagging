{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3c9be85",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7d58811b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "import json\n",
    "\n",
    "import av\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "from transformers import VivitImageProcessor, VivitModel\n",
    "from transformers import AutoImageProcessor, VideoMAEModel\n",
    "from transformers import TimesformerConfig, TimesformerModel\n",
    "from transformers import XCLIPProcessor, XCLIPModel\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "from transformers import BitsAndBytesConfig, LlavaNextVideoForConditionalGeneration, LlavaNextVideoProcessor\n",
    "from transformers import pipeline\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "import librosa\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "from minio import Minio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8570e333-fbc9-4084-b9ce-323eda48c7e1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Auxiliary code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e24136e1-3b3c-40a0-abac-66f84eda93c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "def get_model_params_count(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "def read_video_pyav(container, indices):\n",
    "    \"\"\"\n",
    "    Decode the video with PyAV decoder.\n",
    "\n",
    "    Args:\n",
    "        container (av.container.input.InputContainer): PyAV container.\n",
    "        indices (List[int]): List of frame indices to decode.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: Decoded frames of shape (num_frames, height, width, 3).\n",
    "    \"\"\"\n",
    "    frames = []\n",
    "    container.seek(0)\n",
    "    start_index = indices[0]\n",
    "    end_index = indices[-1]\n",
    "    for i, frame in enumerate(container.decode(video=0)):\n",
    "        if i > end_index:\n",
    "            break\n",
    "        if i >= start_index and i in indices:\n",
    "            frames.append(frame)\n",
    "    if not frames:\n",
    "        raise ValueError(\"No frames were decoded. Check the frame indices and video file.\")\n",
    "    return np.stack([x.to_ndarray(format=\"rgb24\") for x in frames])\n",
    "\n",
    "\n",
    "def sample_frame_indices(clip_len, frame_sample_rate, seg_len):\n",
    "    \"\"\"\n",
    "    Sample a given number of frame indices from the video.\n",
    "\n",
    "    Args:\n",
    "        clip_len (int): Total number of frames to sample.\n",
    "        frame_sample_rate (int): Sample every n-th frame.\n",
    "        seg_len (int): Total number of frames in the video.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: List of sampled frame indices.\n",
    "    \"\"\"\n",
    "    converted_len = int(clip_len * frame_sample_rate)\n",
    "    if seg_len < converted_len:\n",
    "        end_idx = seg_len - 1\n",
    "    else:\n",
    "        end_idx = np.random.randint(converted_len, seg_len)\n",
    "    start_idx = end_idx - converted_len\n",
    "    indices = np.linspace(start_idx, end_idx, num=clip_len)\n",
    "    indices = np.clip(indices, start_idx, end_idx - 1).astype(np.int64)\n",
    "    return indices\n",
    "\n",
    "\n",
    "def process_video(file_path, image_processor, model, clip_len=32, frame_sample_rate=1, device='cpu'):\n",
    "    \"\"\"\n",
    "    Process a single video and return the last_hidden_states.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the video file.\n",
    "        image_processor (VivitImageProcessor): Image processor instance.\n",
    "        model (VivitModel): ViViT model instance.\n",
    "        clip_len (int, optional): Number of frames to sample. Defaults to 32.\n",
    "        frame_sample_rate (int, optional): Sampling rate. Defaults to 1.\n",
    "        device (str, optional): Device to run the model on ('cpu' or 'cuda'). Defaults to 'cpu'.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The last hidden states from the model.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        container = av.open(file_path)\n",
    "        video_stream = container.streams.video[0]\n",
    "        total_frames = video_stream.frames\n",
    "        if total_frames is None:\n",
    "            # Sometimes PyAV cannot retrieve frame count; estimate it\n",
    "            total_frames = int(video_stream.duration * video_stream.average_rate)\n",
    "        \n",
    "        indices = sample_frame_indices(clip_len, frame_sample_rate, total_frames)\n",
    "        video = read_video_pyav(container, indices)\n",
    "        \n",
    "        # Preprocess frames\n",
    "        inputs = image_processor(list(video), return_tensors=\"pt\")\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        \n",
    "        # Forward pass\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        last_hidden_states = outputs.last_hidden_state.cpu()\n",
    "        return last_hidden_states\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7493a948-a1bc-42e7-8bb8-b8008715b047",
   "metadata": {
    "collapsed": false,
    "jp-MarkdownHeadingCollapsed": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## ViViT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a9d8d9-d78a-4e70-9fc2-cc18298000e8",
   "metadata": {},
   "source": [
    "Download the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7af929e0-b82f-48db-87cc-0bd3ff063da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_LOADED = True\n",
    "\n",
    "if not IS_LOADED:\n",
    "    model = VivitModel.from_pretrained(\"google/vivit-b-16x2-kinetics400\")\n",
    "    image_processor = VivitImageProcessor.from_pretrained(\"google/vivit-b-16x2-kinetics400\")\n",
    "    \n",
    "    model.save_pretrained('models/vivit_model')\n",
    "    image_processor.save_pretrained('models/vivit_image_processor')\n",
    "else:\n",
    "    model = VivitModel.from_pretrained(\"models/vivit_model\")\n",
    "    image_processor = VivitImageProcessor.from_pretrained(\"models/vivit_image_processor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02852d9-cf1b-480e-8265-75b8c55ca32d",
   "metadata": {},
   "source": [
    "Download video + move model to gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae238f0b-a9f4-45db-95a6-56e38106662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "data_dir = 'data'\n",
    "video_files = [f for f in os.listdir(data_dir) if f.lower().endswith('.mp4')]\n",
    "video_file = 'Битлджус 2 (Beetlejuice Beetlejuice) - ненужный сиквел хорошего фильма [Глянул на днях].mp4'\n",
    "file_path = os.path.join(data_dir, video_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48bdccb-33ee-40f6-b9f3-1cc2f5559420",
   "metadata": {},
   "source": [
    "Split video into several windows (because the model takes videos with 32 frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef180070-8cac-4784-b086-ee7e49fd6e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "container = av.open(file_path)\n",
    "video_stream = container.streams.video[0]\n",
    "total_frames = video_stream.frames\n",
    "\n",
    "if total_frames == 0:\n",
    "    total_frames = int(video_stream.duration * video_stream.average_rate * video_stream.time_base)\n",
    "\n",
    "WINDOW_SIZE = 32\n",
    "clip_len = 2 * WINDOW_SIZE\n",
    "frame_sample_rate = 10\n",
    "indices = sample_frame_indices(clip_len, frame_sample_rate, total_frames)\n",
    "video = read_video_pyav(container, indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5fe61b1d-2e05-4c52-a688-37293cfe5616",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16183"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "640f7293-9eea-48ff-9220-6c6f93ac7004",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25.0, 647.32, 17)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fps = float(video_stream.average_rate)\n",
    "duration = float(video_stream.duration * video_stream.time_base)\n",
    "frame_sample_rate = max(1, int(round((fps * 64) / 96)))\n",
    "\n",
    "fps, duration, frame_sample_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ff12db-3669-4c87-b01d-57c04940a5ae",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d0d0ba5-02e2-4b74-bc90-ec33fbd0a498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.35 s, sys: 73.9 ms, total: 1.43 s\n",
      "Wall time: 1.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "inputs = image_processor(list(video), return_tensors=\"pt\")\n",
    "inputs = {k: torch.concat(torch.split(v, WINDOW_SIZE, dim=1)).to(device) for k, v in inputs.items()}\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "output = outputs.pooler_output.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e65a7415-f5cd-43f9-babb-732e6549edca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 32, 3, 224, 224])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['pixel_values'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9660d62-cef4-4122-b9bb-7908acf77538",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "Время инференса 1 окна на GPU -- 0.6 секунд\n",
    "\n",
    "Если брать 1 минуту и уменьшить частоту с 25 Гц до 2.5 Гц, то понадобится `math.ceil(150 / 32) * 0.6 = 3` секунды"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb6283d-32a8-4c18-8761-571e90a93644",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## TimeSformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3e4b85-6fd4-4bc3-a422-a4e3f4699886",
   "metadata": {},
   "source": [
    "Downlaod the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc07832e-2b8a-41ec-99b6-1932063cddd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24cae3cc0ada4b3e8ac3890d1bfb552b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/22.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c54efa082e4ce9a23c585be1f56840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/486M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39694e6bd9004daebd567cf9ca334543",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/271 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "IS_LOADED = True\n",
    "\n",
    "if not IS_LOADED:\n",
    "    model = TimesformerModel.from_pretrained(\"facebook/timesformer-base-finetuned-k400\")\n",
    "    image_processor = AutoImageProcessor.from_pretrained(\"MCG-NJU/videomae-base-finetuned-kinetics\")\n",
    "    \n",
    "    model.save_pretrained('models/timesformer_model')\n",
    "    image_processor.save_pretrained('models/timesformer_image_processor')\n",
    "else:\n",
    "    model = TimesformerModel.from_pretrained(\"models/timesformer_model\")\n",
    "    image_processor = AutoImageProcessor.from_pretrained(\"models/timesformer_image_processor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de53f12a-2f80-4f71-9aec-4e3ba5240395",
   "metadata": {},
   "source": [
    "Download video + move model to gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc9842be-cb9d-43d8-b85f-0ca40817d292",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "data_dir = 'data'\n",
    "video_files = [f for f in os.listdir(data_dir) if f.lower().endswith('.mp4')]\n",
    "video_file = 'Битлджус 2 (Beetlejuice Beetlejuice) - ненужный сиквел хорошего фильма [Глянул на днях].mp4'\n",
    "file_path = os.path.join(data_dir, video_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25560cb5-38b5-4bb5-9972-77856c1f7803",
   "metadata": {},
   "source": [
    "Split video into several windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39772671-fd69-4eab-9544-188e5352b691",
   "metadata": {},
   "outputs": [],
   "source": [
    "container = av.open(file_path)\n",
    "video_stream = container.streams.video[0]\n",
    "total_frames = video_stream.frames\n",
    "\n",
    "if total_frames == 0:\n",
    "    total_frames = int(video_stream.duration * video_stream.average_rate * video_stream.time_base)\n",
    "\n",
    "WINDOW_SIZE = 8\n",
    "clip_len = 19 * WINDOW_SIZE\n",
    "frame_sample_rate = 10\n",
    "indices = sample_frame_indices(clip_len, frame_sample_rate, total_frames)\n",
    "video = read_video_pyav(container, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920cad40-a330-4bfb-9a95-be5615883972",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c5f2244f-25bf-4667-92e9-cb2d6e31ed62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.03 s, sys: 79.6 ms, total: 3.11 s\n",
      "Wall time: 3.06 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "inputs = image_processor(list(video), return_tensors=\"pt\")\n",
    "inputs = {k: torch.concat(torch.split(v, WINDOW_SIZE, dim=1)).to(device) for k, v in inputs.items()}\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "output = outputs.last_hidden_state.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e740d8d0-89ae-4e15-abc1-bffe1314cf29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of model's parameters: 121258752\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of model's parameters:\", get_model_params_count(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a634a15-fa45-4c48-8d6e-f7dc309b0758",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Video-MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86a6767-4c15-4971-a495-a9b3c5e10241",
   "metadata": {},
   "source": [
    "Download the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d43a0bf-6f55-4dd4-ab00-2a074a979411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f6e960f1f0e4757882a49bb5bb88739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/725 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43c8a3d0061343d8981dd53530a7f9cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/377M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs.huggingface.co/repos/91/b5/91b59ab5f7189d5b5d9289172d47e785957f89733f8ed6e444edc31a85cef58a/bc053ca2840a038b1068269a4eec06ca569689e9a1ed9376a5b2b8a111be5290?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1727261723&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNzI2MTcyM319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy85MS9iNS85MWI1OWFiNWY3MTg5ZDViNWQ5Mjg5MTcyZDQ3ZTc4NTk1N2Y4OTczM2Y4ZWQ2ZTQ0NGVkYzMxYTg1Y2VmNThhL2JjMDUzY2EyODQwYTAzOGIxMDY4MjY5YTRlZWMwNmNhNTY5Njg5ZTlhMWVkOTM3NmE1YjJiOGExMTFiZTUyOTA%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=GHvYMJVt-qLXcQ1ISkZQI-iQHXgDoONDc3neSHmb9mgLXN5d-c9kwFJbmtYZaLvJHV3PZgJwTLYjSiC1sX5tpR%7E1LhmiRM-RGa5%7EZmOyZPP6gESUizf9moaxxbuHq1prMN4r8pPI8NxmOAnHOPPPb1vQ6%7EkJmupD6taA7B8SnDlIV%7En2FTtA0JDvlmppxviNqVebm0NbGAOoVRJdFyVdK5jM41AzTDrpfx7EAnlg2X8pM3pVcJxg2yw01MFHo-yLi1p-WqNQWAiDc5qNzTx5Y2IsXJnsaGEPoocTG8WBe6r0rIi-ML02MSEEgB-9OLByYxlJWXotBYxZDjRseXt6ZA__&Key-Pair-Id=K3ESJI6DHPFC7: HTTPSConnectionPool(host='cdn-lfs.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f71e260f1d1b4f7f98b46e19de93d13b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:  83%|########3 | 315M/377M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "IS_LOADED = True\n",
    "\n",
    "if not IS_LOADED:\n",
    "    image_processor = AutoImageProcessor.from_pretrained(\"MCG-NJU/videomae-base\")\n",
    "    model = VideoMAEModel.from_pretrained(\"MCG-NJU/videomae-base\")\n",
    "    \n",
    "    model.save_pretrained('models/videomae_model')\n",
    "    image_processor.save_pretrained('models/videomae_image_processor')\n",
    "else:\n",
    "    model = VideoMAEModel.from_pretrained(\"models/videomae_model\")\n",
    "    image_processor = AutoImageProcessor.from_pretrained(\"models/videomae_image_processor\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa76d07-15b4-4d67-ac10-ee7a9cfc3be9",
   "metadata": {},
   "source": [
    "Download video + move model to gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "176c6602-4864-4876-a84f-421ba0f51ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "data_dir = 'data'\n",
    "video_files = [f for f in os.listdir(data_dir) if f.lower().endswith('.mp4')]\n",
    "video_file = 'Битлджус 2 (Beetlejuice Beetlejuice) - ненужный сиквел хорошего фильма [Глянул на днях].mp4'\n",
    "file_path = os.path.join(data_dir, video_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348084ef-f3f5-4727-96d1-13e73274f038",
   "metadata": {},
   "source": [
    "Split video into several windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96772210-86a2-45f1-9480-4cf98a056bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "container = av.open(file_path)\n",
    "video_stream = container.streams.video[0]\n",
    "total_frames = video_stream.frames\n",
    "\n",
    "if total_frames == 0:\n",
    "    total_frames = int(video_stream.duration * video_stream.average_rate * video_stream.time_base)\n",
    "\n",
    "WINDOW_SIZE = 16\n",
    "clip_len = 10 * WINDOW_SIZE\n",
    "frame_sample_rate = 10\n",
    "indices = sample_frame_indices(clip_len, frame_sample_rate, total_frames)\n",
    "video = read_video_pyav(container, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058d6a3c-e50c-4d6d-a31e-978b8eecefb8",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "84e19588-c250-4b86-8122-bc2c4b872667",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eduard/mambaforge/envs/video-tag/lib/python3.12/site-packages/transformers/feature_extraction_utils.py:142: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1720538439675/work/torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  return torch.tensor(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.59 s, sys: 63.5 ms, total: 2.65 s\n",
      "Wall time: 2.62 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "inputs = image_processor(list(video), return_tensors=\"pt\")\n",
    "inputs = {k: torch.concat(torch.split(v, WINDOW_SIZE, dim=1)).to(device) for k, v in inputs.items()}\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "output = outputs.last_hidden_state.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "318f7a13-72a3-4102-a378-8314690a4289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of model's parameters: 86227200\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of model's parameters:\", get_model_params_count(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9f9069-088f-4d56-950c-884ded231701",
   "metadata": {},
   "source": [
    "## X-CLIP (baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea68961-5564-4edb-9590-d99af2850107",
   "metadata": {},
   "source": [
    "Download the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c986cf3f-fc33-46ed-af28-186ccd9c5a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_LOADED = True\n",
    "model_name = \"microsoft/xclip-base-patch16-zero-shot\"\n",
    "\n",
    "if not IS_LOADED:\n",
    "    image_processor = XCLIPProcessor.from_pretrained(model_name)\n",
    "    model = XCLIPModel.from_pretrained(model_name)\n",
    "    \n",
    "    model.save_pretrained('models/xclip_model')\n",
    "    image_processor.save_pretrained('models/xclip_image_processor')\n",
    "else:\n",
    "    model = XCLIPModel.from_pretrained(\"models/xclip_model\")\n",
    "    image_processor = XCLIPProcessor.from_pretrained(\"models/xclip_image_processor\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e0b3d8-d287-419a-a2b0-db390807b6dd",
   "metadata": {},
   "source": [
    "Download video + move model to gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b863dea8-b2a7-4010-ad0f-0f0dda6394df",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "data_dir = 'data'\n",
    "video_files = [f for f in os.listdir(data_dir) if f.lower().endswith('.mp4')]\n",
    "video_file = 'Битлджус 2 (Beetlejuice Beetlejuice) - ненужный сиквел хорошего фильма [Глянул на днях].mp4'\n",
    "file_path = os.path.join(data_dir, video_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e26797b-c2ec-4ed6-a28b-6b50fa541036",
   "metadata": {},
   "source": [
    "Split video into several windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "034becec-b624-4e88-909b-741355446239",
   "metadata": {},
   "outputs": [],
   "source": [
    "container = av.open(file_path)\n",
    "video_stream = container.streams.video[0]\n",
    "total_frames = video_stream.frames\n",
    "\n",
    "if total_frames == 0:\n",
    "    total_frames = int(video_stream.duration * video_stream.average_rate * video_stream.time_base)\n",
    "\n",
    "WINDOW_SIZE = 32\n",
    "clip_len = WINDOW_SIZE\n",
    "frame_sample_rate = 60\n",
    "indices = sample_frame_indices(clip_len, frame_sample_rate, total_frames)\n",
    "video = read_video_pyav(container, indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf77e0a1-1dc8-4da8-81c1-90611c02b9a0",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8fc7f2b7-84c6-46a6-b4f6-7199e97b739f",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = \"\"\"Auto-moto,\n",
    "Anime,\n",
    "Audiobooks,\n",
    "Business,\n",
    "Video games,\n",
    "Interview,\n",
    "Art,\n",
    "Movie,\n",
    "Beauty,\n",
    "Cooking,\n",
    "Life Hacks,\n",
    "Music,\n",
    "Cartoons,\n",
    "News,\n",
    "Training,\n",
    "Hunting and fishing,\n",
    "Politics,\n",
    "Psychology,\n",
    "Journeys,\n",
    "Serials,\n",
    "Sport,\n",
    "Humor,\n",
    "Lifestyle,\n",
    "Realty,\n",
    "Health,\n",
    "Nature,\n",
    "Design,\n",
    "Machinery and equipment,\n",
    "Business and entrepreneurship,\n",
    "Culture,\n",
    "Religion,\n",
    "Construction and renovation,\n",
    "Garden and vegetable garden,\n",
    "Food,\n",
    "Entertainment,\n",
    "Esotericism,\n",
    "The science,\n",
    "Audio,\n",
    "Technology and the Internet,\n",
    "TV shows,\n",
    "For children,\n",
    "Hobby,\n",
    "Various,\n",
    "Animals,\n",
    "News and media,\n",
    "Films,\n",
    "Bloggers,\n",
    "Podcasts,\n",
    "\"\"\"\n",
    "\n",
    "text_prompt = [f\"The video belongs to category '{x}'\" for x in categories.split(',\\n') if x.strip() != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f70cbfad-5216-4dfa-aa1b-30990817140f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([48, 14])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "61954d10-f647-473c-bded-3b8af0ded671",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([48, 14]), torch.Size([1, 32, 3, 224, 224]))"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['attention_mask'].shape, inputs['pixel_values'].shape,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3723ae0-c814-4259-a5e8-70373e00c43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b4074e64-b6e0-40d2-aab6-40c2412c3c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 859 ms, sys: 232 ms, total: 1.09 s\n",
      "Wall time: 2.08 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "inputs = image_processor(\n",
    "    text=text_prompt,\n",
    "    videos=list(video),\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True\n",
    ")\n",
    "\n",
    "inputs['pixel_values'] = torch.concat(torch.split(inputs['pixel_values'], WINDOW_SIZE, dim=1))\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "# forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8129c3-5d7e-4bd4-a9aa-580027a60fe3",
   "metadata": {},
   "source": [
    "Какое место заняла истинная категория (45, \"Фильмы\")?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1febfe49-57ef-4388-8b3f-b56876c00f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 3, 224, 224])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['pixel_values'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e824d39f-f9d8-40f8-a654-eeb6754a80e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 48])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits_per_video.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fbf11946-6f52-4c42-b48a-2079b3528741",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 768])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.vision_model_output.pooler_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25c57c29-8690-4083-b537-00eda20914a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.video_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9051aed6-16cd-461c-9fd3-e634f39761d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.mit_output.pooler_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d7ad88f4-f3c6-425e-b349-31b2d2d7e7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['logits_per_video', 'logits_per_text', 'text_embeds', 'video_embeds', 'text_model_output', 'vision_model_output', 'mit_output'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b026a6ec-9bad-49fb-9a5b-d7a5f252420b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Правильная категория заняла 8-ое место\n",
      "0.116 | The video belongs to category 'Art'\n",
      "0.103 | The video belongs to category 'Interview'\n",
      "0.101 | The video belongs to category 'Esotericism'\n",
      "0.045 | The video belongs to category 'Design'\n",
      "0.039 | The video belongs to category 'Beauty'\n",
      "0.037 | The video belongs to category 'Journeys'\n",
      "0.037 | The video belongs to category 'Sport'\n",
      "0.036 | The video belongs to category 'Films'\n"
     ]
    }
   ],
   "source": [
    "logits = outputs.logits_per_video.cpu()\n",
    "\n",
    "prob = logits.softmax(dim=1).numpy().reshape(-1)\n",
    "order = logits.argsort(dim=1, descending=True).numpy().reshape(-1)\n",
    "place = np.flatnonzero(order == 45)[0] + 1\n",
    "\n",
    "print(f\"Правильная категория заняла {place}-ое место\")\n",
    "for x, y in zip(np.array(text_prompt)[order[:place]], prob[order[:place]]):\n",
    "    print(round(y, 3), '|', x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4428c24a-f128-44e5-86d4-48b1afbe8311",
   "metadata": {},
   "source": [
    "Inference (russian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76c3de13-07ed-48d7-bdfc-da16b4a0fa81",
   "metadata": {},
   "outputs": [],
   "source": [
    "rus_categories = \"\"\"\n",
    "Авто-мото\n",
    "Аниме\n",
    "Аудиокниги\n",
    "Бизнес\n",
    "Видеоигры\n",
    "Интервью\n",
    "Искусство\n",
    "Кино\n",
    "Красота\n",
    "Кулинария\n",
    "Лайфхаки\n",
    "Музыка\n",
    "Мультфильмы\n",
    "Новости\n",
    "Обучение\n",
    "Охота_и_рыбалка\n",
    "Политика\n",
    "Психология\n",
    "Путешествия\n",
    "Сериалы\n",
    "Спорт\n",
    "Юмор\n",
    "Лайфстайл\n",
    "Недвижимость\n",
    "Здоровье\n",
    "Природа\n",
    "Дизайн\n",
    "Техника_и_оборудование\n",
    "Бизнес_и_предпринимательство\n",
    "Культура\n",
    "Религия\n",
    "Строительство_и_ремонт\n",
    "Сад_и_огород\n",
    "Еда\n",
    "Развлечения\n",
    "Эзотерика\n",
    "Наука\n",
    "Аудио\n",
    "Технологии_и_интернет\n",
    "Телепередачи\n",
    "Детям\n",
    "Хобби\n",
    "Разное\n",
    "Животные\n",
    "Новости_и_СМИ\n",
    "Фильмы\n",
    "Блогеры\n",
    "\"\"\"\n",
    "\n",
    "rus_text_prompt = [f\"Видео принадлежит категории '{x}'\" for x in rus_categories.split() if x.strip() != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "daf37f1b-72a8-4151-a120-1faa97548b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 613 ms, sys: 24.9 ms, total: 638 ms\n",
      "Wall time: 615 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "inputs = image_processor(\n",
    "    text=rus_text_prompt,\n",
    "    videos=list(video),\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True\n",
    ")\n",
    "\n",
    "inputs['pixel_values'] = torch.concat(torch.split(inputs['pixel_values'], WINDOW_SIZE, dim=1))\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "# forward pass\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c4ff11-7c31-4b6a-a500-8e9007d39139",
   "metadata": {},
   "source": [
    "Какое место заняла истинная категория (45, \"Фильмы\")?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc46fd49-2221-4c17-9c5a-46d5a2839144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Правильная категория заняла 1-ое место\n",
      "0.099 | The video belongs to category 'Films'\n"
     ]
    }
   ],
   "source": [
    "logits = outputs.logits_per_video.cpu()\n",
    "\n",
    "prob = logits.softmax(dim=1).numpy().reshape(-1)\n",
    "order = logits.argsort(dim=1, descending=True).numpy().reshape(-1)\n",
    "place = np.flatnonzero(order == 45)[0] + 1\n",
    "\n",
    "print(f\"Правильная категория заняла {place}-ое место\")\n",
    "for x, y in zip(np.array(text_prompt)[order[:place]], prob[order[:place]]):\n",
    "    print(round(y, 3), '|', x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d3c3d4-196f-4714-958c-111f6e297eb7",
   "metadata": {},
   "source": [
    "Размер модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4e4adb44-5913-49cf-bb7e-5c509d508303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194941441"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model_params_count(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78335df-277f-44a3-a334-fa12fa952c5a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Whisper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5908694d-705b-4154-bf41-2ac2bc9cebe0",
   "metadata": {},
   "source": [
    "Download the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee65714c-1b2a-4d5e-a215-0ea3e6a2130a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36811468907e4d7b9e59809021dc51e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "IS_LOADED = True\n",
    "\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "model_id = \"openai/whisper-large-v3\"\n",
    "\n",
    "if not IS_LOADED:\n",
    "    model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "        model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    "    )\n",
    "    processor = AutoProcessor.from_pretrained(model_id)\n",
    "    \n",
    "    model.save_pretrained('models/whisper_model')\n",
    "    processor.save_pretrained('models/whisper_processor')\n",
    "else:\n",
    "    model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "        \"models/whisper_model\", torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    "    )\n",
    "    processor = AutoProcessor.from_pretrained(\"models/whisper_processor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d7c8a21-aad7-4f51-a945-f38937d796c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1541570560"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "model.eval()\n",
    "get_model_params_count(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9fc48f3a-4a7c-4432-9ddb-ab0275f078a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['text'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3ef4ee9-a262-4a0d-88e3-a2a95f5662c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34a32e2a812f4a66bfdee9e4b6977ed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/480 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3455f3b9719f429f8e33ae3e8208d9c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "(…)-00000-of-00001-913508124a40cb97.parquet:   0%|          | 0.00/1.98M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f32b7f7cfce54383b895f771fe1b6e15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Mr. Quilter is the apostle of the middle classes, and we are glad to welcome his gospel. Nor is Mr. Quilter's manner less interesting than his matter. He tells us that at this festive season of the year, with Christmas and roast beef looming before us, similes drawn from eating and its results occur most readily to the mind. He has grave doubts whether Sir Frederick Leighton's work is really Greek after all, and can discover in it but little of rocky Ithaca. Linnell's pictures are a sort of Upguards and Adam paintings, and Mason's exquisite idylls are as national as a jingo poem. Mr. Burkett Foster's landscapes smile at one much in the same way that Mr. Carker used to flash his teeth. And Mr. John Collier gives his sitter a cheerful slap on the back before he says, like a shampooer in a Turkish bath, Next man!\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "dataset = load_dataset(\"distil-whisper/librispeech_long\", \"clean\", split=\"validation\")\n",
    "sample = dataset[0][\"audio\"]\n",
    "\n",
    "result = pipe(sample)\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0df73a7c-7381-40d7-8833-37237397e606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'path': '0d38672e0bbdbdc460af55b8bb84a15b2730db2819f2af64f9c777d4d586f2de',\n",
       " 'array': array([0.00238037, 0.0020752 , 0.00198364, ..., 0.00024414, 0.00048828,\n",
       "        0.0005188 ]),\n",
       " 'sampling_rate': 16000}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][\"audio\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1bcd80d0-83bf-4316-9d70-df69ff438267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_features': tensor([[[ 0.0436, -0.1703, -0.1855,  ...,  0.1478,  0.1967,  0.3374],\n",
       "         [ 0.1411, -0.0728, -0.0880,  ...,  0.2454,  0.2942,  0.4350],\n",
       "         [-0.0206, -0.0893, -0.0648,  ...,  0.4284,  0.4698,  0.4153],\n",
       "         ...,\n",
       "         [-0.6398, -0.6398, -0.6398,  ..., -0.0424, -0.1619, -0.0533],\n",
       "         [-0.6398, -0.6398, -0.6398,  ..., -0.1244, -0.1859, -0.0593],\n",
       "         [-0.6398, -0.6398, -0.6398,  ..., -0.1040, -0.1921, -0.0369]]])}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processor(sample[\"array\"], sampling_rate=sample[\"sampling_rate\"], return_tensors=\"pt\", dtype=torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fd959df7-3d2b-42a4-8c82-a336d1518df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the last hidden state: torch.Size([1, 1500, 1280])\n"
     ]
    }
   ],
   "source": [
    "sample = dataset[0][\"audio\"]\n",
    "inputs = processor(sample[\"array\"], sampling_rate=sample[\"sampling_rate\"], return_tensors=\"pt\")\n",
    "input_features = inputs.input_features.type(torch.float16).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Forward pass through the encoder\n",
    "    encoder_outputs = model.model.encoder(input_features)\n",
    "\n",
    "# Access the last hidden state\n",
    "last_hidden_state = encoder_outputs.last_hidden_state\n",
    "\n",
    "print(\"Shape of the last hidden state:\", last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e529b8a-2984-4b3b-aa00-8894fcf753c3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Wav2Vec-2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052a7def-91d4-4391-8167-11f60d314924",
   "metadata": {},
   "source": [
    "Загрузка модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb2fab65-b707-4bb7-bdb0-3915228bcb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_LOADED = True\n",
    "\n",
    "if not IS_LOADED:\n",
    "    MODEL_ID = \"jonatasgrosman/wav2vec2-large-xlsr-53-russian\"\n",
    "    \n",
    "    processor = Wav2Vec2Processor.from_pretrained(MODEL_ID)\n",
    "    model = Wav2Vec2ForCTC.from_pretrained(MODEL_ID)\n",
    "    \n",
    "    model.save_pretrained('models/wav2vec2_model')\n",
    "    processor.save_pretrained('models/wav2vec2_processor')\n",
    "else:\n",
    "    model = Wav2Vec2ForCTC.from_pretrained(\"models/wav2vec2_model\")\n",
    "    processor = Wav2Vec2Processor.from_pretrained(\"models/wav2vec2_processor\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8834a2bb-5d91-42e9-af24-f61ba21a18db",
   "metadata": {},
   "source": [
    "Download video + move model to gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d054c8ee-eeea-40ae-a095-bed606c5af0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Vec2ForCTC(\n",
       "  (wav2vec2): Wav2Vec2Model(\n",
       "    (feature_extractor): Wav2Vec2FeatureEncoder(\n",
       "      (conv_layers): ModuleList(\n",
       "        (0): Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(1, 512, kernel_size=(10,), stride=(5,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (1-4): 4 x Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(3,), stride=(2,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "        (5-6): 2 x Wav2Vec2LayerNormConvLayer(\n",
       "          (conv): Conv1d(512, 512, kernel_size=(2,), stride=(2,))\n",
       "          (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation): GELUActivation()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (feature_projection): Wav2Vec2FeatureProjection(\n",
       "      (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "      (projection): Linear(in_features=512, out_features=1024, bias=True)\n",
       "      (dropout): Dropout(p=0.05, inplace=False)\n",
       "    )\n",
       "    (encoder): Wav2Vec2EncoderStableLayerNorm(\n",
       "      (pos_conv_embed): Wav2Vec2PositionalConvEmbedding(\n",
       "        (conv): ParametrizedConv1d(\n",
       "          1024, 1024, kernel_size=(128,), stride=(1,), padding=(64,), groups=16\n",
       "          (parametrizations): ModuleDict(\n",
       "            (weight): ParametrizationList(\n",
       "              (0): _WeightNorm()\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (padding): Wav2Vec2SamePadLayer()\n",
       "        (activation): GELUActivation()\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.05, inplace=False)\n",
       "      (layers): ModuleList(\n",
       "        (0-23): 24 x Wav2Vec2EncoderLayerStableLayerNorm(\n",
       "          (attention): Wav2Vec2SdpaAttention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (dropout): Dropout(p=0.05, inplace=False)\n",
       "          (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (feed_forward): Wav2Vec2FeedForward(\n",
       "            (intermediate_dropout): Dropout(p=0.05, inplace=False)\n",
       "            (intermediate_dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "            (output_dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "            (output_dropout): Dropout(p=0.05, inplace=False)\n",
       "          )\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (lm_head): Linear(in_features=1024, out_features=39, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eccc81f-ebc8-450e-847e-ef577278b456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "315478695"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_model_params_count(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d67f6bb-1558-4a37-9e00-2dc7cf6e9998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'processor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m [speech_file_to_array_fn(item) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m test_dataset]\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Convert the audio into a format suitable for Wav2Vec2\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mprocessor\u001b[49m([item[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspeech\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m test_dataset], sampling_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16_000\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     49\u001b[0m inputs \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m inputs\u001b[38;5;241m.\u001b[39mitems()}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'processor' is not defined"
     ]
    }
   ],
   "source": [
    "# Preprocessing the datasets.\n",
    "# We need to read the audio files as arrays\n",
    "def extract_audio_from_video(video_path, output_audio_path=\"temp_audio.wav\", duration=60):\n",
    "    \"\"\"\n",
    "    Extract audio from the first `duration` seconds of the video.\n",
    "\n",
    "    Args:\n",
    "    video_path (str): Path to the input video file.\n",
    "    output_audio_path (str): Path to save the extracted audio file.\n",
    "    duration (int): The duration of audio to extract in seconds (default: 60 seconds).\n",
    "\n",
    "    Returns:\n",
    "    str: Path to the saved audio file.\n",
    "    \"\"\"\n",
    "    video_clip = VideoFileClip(video_path)\n",
    "    \n",
    "    # Extract only the first `duration` seconds of audio\n",
    "    audio_clip = video_clip.audio.subclip(0, duration)\n",
    "    \n",
    "    # Save the audio to the specified path\n",
    "    audio_clip.write_audiofile(output_audio_path, codec='pcm_s16le')\n",
    "    \n",
    "    # Close the clip to release resources\n",
    "    video_clip.close()\n",
    "    audio_clip.close()\n",
    "    \n",
    "    return output_audio_path\n",
    "\n",
    "\n",
    "def speech_file_to_array_fn(batch):\n",
    "    # Extract the audio from the mp4 file\n",
    "    audio_path = extract_audio_from_video(batch[\"path\"])\n",
    "\n",
    "    # Load the extracted audio using librosa\n",
    "    speech_array, sampling_rate = librosa.load(audio_path, sr=16000)\n",
    "\n",
    "    # Prepare for Wav2Vec2 inference\n",
    "    batch[\"speech\"] = speech_array\n",
    "    return batch\n",
    "\n",
    "\n",
    "test_dataset = [\n",
    "    {\"path\": \"data/49.0_bloggers/Аниме  ＂Волшебница и злой офицер＂.mp4\"},\n",
    "]\n",
    "test_dataset = [speech_file_to_array_fn(item) for item in test_dataset]\n",
    "\n",
    "# Convert the audio into a format suitable for Wav2Vec2\n",
    "inputs = processor([item[\"speech\"] for item in test_dataset], sampling_rate=16_000, return_tensors=\"pt\", padding=True)\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e467fd-b93f-4e1b-896e-d774351824a2",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b333daeb-fd83-4ab5-a905-044e30b5ac87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Prediction: друз я всем брвет вонагоналя оне могает с вами макс еслинлкам разгово давноя вы с своей второй половенькой со свое женое  ебовницы   чутка сое девошкое смотреле что-нибудь романтическое нежно приятное где а вы деяте стипомни только снемашкое но еще зруб другу такот сегодно я вас засталлю посмотреть месте слебимом челоедувся быт куртое гадте а упкорм дите читься бзете како-то пробушенный свет сет его бнинку и включите тонима  если вас еще не убедил  тодайте покажонтреля расскажу о б это немышке я надеюсь что вом захочется ты сдеть поство пролитвемя слебины роднымите боле подткою хороше вес и почем дастоми пважно етноно  сегодня нас занимаю тысячи двацятого года жедисть даже второй сезон сейчасны о нем поэтому яочень хочу чтобы вы ты фонули сегодня павеже как и пону я приброснотратого немо  сенимо больше погнале смотреться ми паено         мире охоченом гнуснобюдянем зло организации которасторгается и ечтожет се своем пути мы следуем заковавным дохновителем миры бочи блистящего мом злономерные гругпыт мира состредичкой точность организут халс оставля по сле себя разрушение однако судба принимает нежетны порот этадеужкволше блиться поэменги ока н мое смелшает выступить против орамизации мира оружобые силы магии по колебивым чувство справедливости ни больствуется грозный силый против хауса удивительно любира сперо скляда а чегонсмелый деошкаволошебници любов чувство чуждые тенному мирузных мыфинации рассведця в сердце миры конфликтуры беж длаяльностью к организации и в бощье притенныни чувствуи кни море бирасталкивается стутони борьбое вот такое го  безу крутое без элементов нет без элментов войны борьбы тоесть это не просто а от в тондаке не посто глупая романтика милограму где постоянные словое такдане нет это война или бо это то что диствител наши жизни происходо общем- то тедя что вом поннавилась сем спасибо вы быле маконаляне могают свое бо романтичный макс с достарствует  акстарчилкридоску нет сто что арпетов то бую стает а кто бы т комментае писать быслатьшением рассматривает кто подпишется на мой канал не тыли  где что ты  сперься тебе могу сами спокое брашатсясо цемпака\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(inputs['input_values'], attention_mask=inputs['attention_mask'])\n",
    "\n",
    "# Decode predictions\n",
    "logits = output.logits\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "predicted_sentences = processor.batch_decode(predicted_ids)\n",
    "\n",
    "# Print predictions and references\n",
    "for i, predicted_sentence in enumerate(predicted_sentences):\n",
    "    print(\"-\" * 100)\n",
    "    print(\"Prediction:\", predicted_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bce3d11-2f95-43b9-bdbb-de9fb7858864",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10359040])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['input_values'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5b326281-8d9f-4889-acb2-2cb3bedce041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "Your token has been saved to /home/eduard/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5af25c787514cefb1d0bd811b6c57d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "n_shards.json:   0%|          | 0.00/17.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aa0637a2cda4b3a9f516de6410193ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ru_train_0.tar:   0%|          | 0.00/976M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "201bf433f0bb4d03a3c9b402bcd36127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ru_dev_0.tar:   0%|          | 0.00/392M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ae0c75f25c64df0b6aaab43b3d2c0b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ru_test_0.tar:   0%|          | 0.00/397M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe3a5631ce249e190bb1586bccd484d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ru_other_0.tar:   0%|          | 0.00/597M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error while downloading from https://cdn-lfs-us-1.huggingface.co/repos/a3/86/a386bf65687d8a6928c1ea57c383aa3faade32f5171150e25af3fc1cfc273db8/ed2a884829f1d4fc92bf654699fa5b518afdf867155b59cd38e4b458c50450d8?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27ru_other_0.tar%3B+filename%3D%22ru_other_0.tar%22%3B&response-content-type=application%2Fx-tar&Expires=1727445161&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcyNzQ0NTE2MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmh1Z2dpbmdmYWNlLmNvL3JlcG9zL2EzLzg2L2EzODZiZjY1Njg3ZDhhNjkyOGMxZWE1N2MzODNhYTNmYWFkZTMyZjUxNzExNTBlMjVhZjNmYzFjZmMyNzNkYjgvZWQyYTg4NDgyOWYxZDRmYzkyYmY2NTQ2OTlmYTViNTE4YWZkZjg2NzE1NWI1OWNkMzhlNGI0NThjNTA0NTBkOD9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSomcmVzcG9uc2UtY29udGVudC10eXBlPSoifV19&Signature=rN9sq6mipUcfKH1V-rWdGzj2gb7ed4OF1uZG00PalTS7Wr76wC2gy6383MbXkYZT9Df2YL%7ElBJXzdpdtB8d%7E6tmPeCr8-cMlMH-xrH6%7ESuqe944%7E90E3BahL6bYP2wzIVt2NHfPOy9LeTCkLqgWX%7EnekWzfdalGgRWS8PmjEwtvmR8TwvKyGkOFJxG6S9V3ylJK3VuvuSHq7XRWcrp5BGD%7EKyussgUvakYtR6ZwrUYzM6HqbgtStOQUEFLBcqUmoiSifn134LxHO27Q3UrJcnocOf%7EfQPElZNC2lw-lkHMg7A-od%7EbCHPiWHfbAwu4-Tiwovr2fncVBFxDfYBCUOGQ__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.huggingface.co', port=443): Read timed out.\n",
      "Trying to resume download...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4758e260c55641b6a6c4796708531275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ru_other_0.tar:  32%|###1      | 189M/597M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca5d71b3ce85429f9693f4bf26084e8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ru_invalidated_0.tar:   0%|          | 0.00/387M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a15ac6f1af441df83fadfda08beb041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ru_validated_0.tar:   0%|          | 0.00/1.51G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7036815a3a249949f559280b3584687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ru_validated_1.tar:   0%|          | 0.00/1.43G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52eb2b4d527d49ea815e1f4b4eca3a72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ru_validated_2.tar:   0%|          | 0.00/1.60G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91305fc3b3374260b45c60b4cb65919e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ru_validated_3.tar:   0%|          | 0.00/1.38G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b53e862a9b0412cbd748f192d854c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "ru_validated_4.tar:   0%|          | 0.00/114M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ab91a70c174b82ae7fbf7cbad39102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "transcript/ru/train.tsv:   0%|          | 0.00/9.85M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f47786b246f41f3860b1137bd10df25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "transcript/ru/dev.tsv:   0%|          | 0.00/3.73M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b9b0bddf8eb444baaef9ab915c069cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "transcript/ru/test.tsv:   0%|          | 0.00/3.64M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d8e34ac31aa4cc89a9679c683bd917a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "transcript/ru/other.tsv:   0%|          | 0.00/6.55M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9f3998a5f7a470e89fed70ea33694ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "transcript/ru/invalidated.tsv:   0%|          | 0.00/3.79M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc56fabd7274dbe965fddcc5c888f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validated.tsv:   0%|          | 0.00/61.3M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ebd3ad592cd4c7f82e6201c5aeb7a9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading metadata...: 26377it [00:00, 323197.70it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "085586d5976e49c2bd5431af6cb88d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading metadata...: 10203it [00:00, 315544.67it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3dd071d45d04b81b873e6c450ba0c7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading metadata...: 10203it [00:00, 316167.12it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fc71bfb13cf477895f8fb375e1e3745",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating other split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading metadata...: 17456it [00:00, 320471.02it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16770927d074b7ebdc9362ed8d619ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating invalidated split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading metadata...: 10018it [00:00, 316376.06it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe917b16379d428eae3c6d7a0ca77fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validated split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Reading metadata...: 0it [00:00, ?it/s]\u001b[A\n",
      "Reading metadata...: 32351it [00:00, 323479.46it/s]\u001b[A\n",
      "Reading metadata...: 64699it [00:00, 307393.36it/s]\u001b[A\n",
      "Reading metadata...: 95493it [00:00, 293935.88it/s]\u001b[A\n",
      "Reading metadata...: 124951it [00:00, 289836.97it/s]\u001b[A\n",
      "Reading metadata...: 163387it [00:00, 292140.27it/s]\u001b[A\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "TOKEN = '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'\n",
    "SAMPLES = 5\n",
    "\n",
    "login(token=TOKEN)\n",
    "dataset = load_dataset(\n",
    "    \"mozilla-foundation/common_voice_17_0\",\n",
    "    \"ru\",\n",
    "    split=f\"test[:{SAMPLES}]\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8afa18a7-9b5a-450c-90e9-478dc20dd360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b8f1d4791e94f1da4e3336eecd0fae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/5 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We need to read the audio files as arrays\n",
    "def speech_file_to_array_fn_v2(batch):\n",
    "    speech_array, sampling_rate = librosa.load(batch[\"path\"], sr=16_000)\n",
    "    batch[\"speech\"] = speech_array\n",
    "    batch[\"sentence\"] = batch[\"sentence\"].upper()\n",
    "    return batch\n",
    "\n",
    "dataset = dataset.map(speech_file_to_array_fn_v2)\n",
    "inputs_2 = processor(dataset[\"speech\"], sampling_rate=16_000, return_tensors=\"pt\", padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "15896eab-c8e9-4c86-b61d-d7f862bcf53a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Prediction: масштабы финансово-экономического кризиса и темпывого распространения застали самых опытных специалистов мирах врасплох\n",
      "Target: МАСШТАБЫ ФИНАНСОВО-ЭКОНОМИЧЕСКОГО КРИЗИСА И ТЕМПЫ ЕГО РАСПРОСТРАНЕНИЯ ЗАСТАЛИ САМЫХ ОПЫТНЫХ СПЕЦИАЛИСТОВ МИРА ВРАСПЛОХ.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prediction: к сожалению эти предложения не носли отражения в тексте\n",
      "Target: К СОЖАЛЕНИЮ, ЭТИ ПРЕДЛОЖЕНИЯ НЕ НАШЛИ ОТРАЖЕНИЯ В ТЕКСТЕ.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prediction: наконец я хочу поблагодарить всех присутствующих здесь сегодня участников\n",
      "Target: НАКОНЕЦ, Я ХОЧУ ПОБЛАГОДАРИТЬ ВСЕХ ПРИСУТСТВУЮЩИХ ЗДЕСЬ СЕГОДНЯ УЧАСТНИКОВ.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prediction: толпа звереет будет тереться ощути непножки стоглавая вожь е\n",
      "Target: ТОЛПА ОЗВЕРЕЕТ, БУДЕТ ТЕРЕТЬСЯ, ОЩЕТИНИТ НОЖКИ СТОГЛАВАЯ ВОШЬ.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Prediction: и допровольчество это не понасея\n",
      "Target: ДОБРОВОЛЬЧЕСТВО — ЭТО НЕ ПАНАЦЕЯ.\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output_2 = model(inputs_2['input_values'].to(device), attention_mask=inputs_2['attention_mask'].to(device))\n",
    "\n",
    "# Decode predictions\n",
    "logits = output_2.logits\n",
    "predicted_ids = torch.argmax(logits, dim=-1)\n",
    "predicted_sentences = processor.batch_decode(predicted_ids)\n",
    "\n",
    "# Print predictions and references\n",
    "for i, predicted_sentence in enumerate(predicted_sentences):\n",
    "    print(\"-\" * 100)\n",
    "    print(\"Prediction:\", predicted_sentence)\n",
    "    print(\"Target:\", dataset['sentence'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34ca87c-7bab-4e4c-9c40-0ceda1ca7f16",
   "metadata": {},
   "source": [
    "**Вывод**\n",
    "\n",
    "Модель -- какашка, не использовать"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017cac2f-4304-41a2-a253-70a2be7c1d4b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## GigaAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fee3abb5-c052-43eb-b73f-78c655096f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import soundfile as sf\n",
    "from omegaconf import OmegaConf\n",
    "import locale\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "# !wget -P /models/giga_am/ https://n-ws-q0bez.s3pd12.sbercloud.ru/b-ws-q0bez-jpv/GigaAM/ssl_model_weights.ckpt\n",
    "# !wget -P /models/giga_am/ https://n-ws-q0bez.s3pd12.sbercloud.ru/b-ws-q0bez-jpv/GigaAM/encoder_config.yaml\n",
    "# !wget -P /models/giga_am/ https://n-ws-q0bez.s3pd12.sbercloud.ru/b-ws-q0bez-jpv/GigaAM/example.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3657417f-2390-491e-984e-ba331a6d2cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-09-25 18:45:50 nemo_logging:349] /tmp/ipykernel_35514/1427804660.py:21: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "      ckpt = torch.load(model_weights, map_location=\"cpu\")\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "def extract_audio_from_video(video_path, output_audio_path=\"temp_audio.wav\"):\n",
    "    video_clip = VideoFileClip(video_path)\n",
    "    video_clip.audio.write_audiofile(output_audio_path, codec='pcm_s16le')\n",
    "    return output_audio_path\n",
    "\n",
    "\n",
    "class SpecScaler(torch.nn.Module):\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.log(x.clamp_(1e-9, 1e9))\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "dirname = 'models/giga_am/'\n",
    "encoder_config = dirname+\"encoder_config.yaml\"\n",
    "model_weights = dirname+\"ssl_model_weights.ckpt\"\n",
    "audio_path = dirname+\"example.wav\"\n",
    "\n",
    "conf = OmegaConf.load(encoder_config)\n",
    "\n",
    "encoder = hydra.utils.instantiate(conf.encoder)\n",
    "ckpt = torch.load(model_weights, map_location=\"cpu\")\n",
    "encoder.load_state_dict(ckpt, strict=True)\n",
    "encoder.to(device)\n",
    "encoder.eval()\n",
    "\n",
    "feature_extractor = hydra.utils.instantiate(conf.feature_extractor)\n",
    "\n",
    "audio_signal, _ = sf.read(audio_path, dtype=\"float32\")\n",
    "features = feature_extractor(torch.tensor(audio_signal).float())\n",
    "features = features.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "61b74839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded signal shape: torch.Size([1, 768, 283])\n",
      "CPU times: user 68.5 ms, sys: 26.1 ms, total: 94.7 ms\n",
      "Wall time: 331 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with torch.no_grad():\n",
    "    encoded, _ = encoder.forward(\n",
    "        audio_signal=features.unsqueeze(0),\n",
    "        length=torch.tensor([features.shape[-1]]).to(device),\n",
    "    )\n",
    "    print(f\"encoded signal shape: {encoded.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c04d7a",
   "metadata": {},
   "source": [
    "Кодируем аудио со всех видео"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "03e5413f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in temp_audio.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    }
   ],
   "source": [
    "def extract_audio_from_video(video_path, output_audio_path=\"temp_audio.wav\", duration=60):\n",
    "    video_clip = VideoFileClip(video_path)\n",
    "    \n",
    "    # Extract only the first `duration` seconds of audio\n",
    "    audio_clip = video_clip.audio.subclip(0, duration)\n",
    "    \n",
    "    # Save the audio to the specified path\n",
    "    audio_clip.write_audiofile(output_audio_path, codec='pcm_s16le')\n",
    "    \n",
    "    # Close the clip to release resources\n",
    "    video_clip.close()\n",
    "    audio_clip.close()\n",
    "    \n",
    "    return output_audio_path\n",
    "\n",
    "\n",
    "def speech_file_to_array_fn(batch):\n",
    "    # Extract the audio from the mp4 file\n",
    "    audio_path = extract_audio_from_video(batch[\"path\"])\n",
    "\n",
    "    # Load the extracted audio using librosa\n",
    "    speech_array, sampling_rate = librosa.load(audio_path, sr=16000)\n",
    "\n",
    "    # Prepare for Wav2Vec2 inference\n",
    "    batch[\"speech\"] = speech_array\n",
    "    return batch\n",
    "\n",
    "\n",
    "test_dataset = [\n",
    "    {\"path\": \"data/49.0_bloggers/Аниме  ＂Волшебница и злой офицер＂.mp4\"},\n",
    "]\n",
    "test_dataset = [speech_file_to_array_fn(item) for item in test_dataset]\n",
    "test_dataset[0]['speech'].shape\n",
    "features_2 = feature_extractor(torch.tensor(test_dataset[0]['speech']).float()).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c02618d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded signal shape: torch.Size([1, 768, 1501])\n",
      "CPU times: user 13.9 ms, sys: 11.8 ms, total: 25.7 ms\n",
      "Wall time: 37.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "with torch.no_grad():\n",
    "    encoded_2, _ = encoder.forward(\n",
    "        audio_signal=features_2.unsqueeze(0),\n",
    "        length=torch.tensor([features_2.shape[-1]]).to(device),\n",
    "    )\n",
    "    print(f\"encoded signal shape: {encoded_2.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32f6a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_signal, _ = sf.read(audio_path, dtype=\"float32\")\n",
    "features = feature_extractor(torch.tensor(audio_signal).float())\n",
    "features = features.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd914aab-e257-4cba-83d9-d6868201a80b",
   "metadata": {},
   "source": [
    "## Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3f427b85-f366-47e1-b6f0-f0a8b496e54f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lvl</th>\n",
       "      <th>parent id</th>\n",
       "      <th>name</th>\n",
       "      <th>name (eng)</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>url1</th>\n",
       "      <th>url2</th>\n",
       "      <th>url3</th>\n",
       "      <th>url4</th>\n",
       "      <th>url5</th>\n",
       "      <th>url6</th>\n",
       "      <th>url7</th>\n",
       "      <th>url8</th>\n",
       "      <th>url9</th>\n",
       "      <th>url10</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Авто-мото</td>\n",
       "      <td>Auto-moto</td>\n",
       "      <td>Вадим</td>\n",
       "      <td>https://rutube.ru/video/77fb221d8c1e75da78bf40...</td>\n",
       "      <td>https://rutube.ru/video/a3a5e23a53a4f295210d79...</td>\n",
       "      <td>https://rutube.ru/shorts/f508b3c1b7efbd72a710f...</td>\n",
       "      <td>https://rutube.ru/video/b2784e7803b339ec734609...</td>\n",
       "      <td>https://rutube.ru/video/671040092dd0f2f25da6ce...</td>\n",
       "      <td>https://rutube.ru/video/a4f693322a0b3a31d2f3e4...</td>\n",
       "      <td>https://rutube.ru/video/460d0196cbfe0a76eb3c01...</td>\n",
       "      <td>https://rutube.ru/video/d83bd4cda356071372e701...</td>\n",
       "      <td>https://rutube.ru/video/0d6f5d3d204b3bcc24d62f...</td>\n",
       "      <td>https://rutube.ru/video/f1869f4b1e664a7886ff86...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Аниме</td>\n",
       "      <td>Anime</td>\n",
       "      <td>Вадим</td>\n",
       "      <td>https://rutube.ru/video/71bae0ad0ee61339fc8fae...</td>\n",
       "      <td>https://rutube.ru/video/85105a8dee2f1fade90e39...</td>\n",
       "      <td>https://rutube.ru/video/4313978b579b72bb9a19fc...</td>\n",
       "      <td>https://rutube.ru/video/09577d13d97015440875a8...</td>\n",
       "      <td>https://rutube.ru/video/d9229991afcc92464e04d3...</td>\n",
       "      <td>https://rutube.ru/video/6c96553552c8f88866e5f2...</td>\n",
       "      <td>https://rutube.ru/video/ade8f3276e6312e86a9ce5...</td>\n",
       "      <td>https://rutube.ru/video/5e6a566bea497140f58bc0...</td>\n",
       "      <td>https://rutube.ru/video/2e6c5019183bea0a449474...</td>\n",
       "      <td>https://rutube.ru/video/b7de1ae017b850e5f20152...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Аудиокниги</td>\n",
       "      <td>Audiobooks</td>\n",
       "      <td>Вадим</td>\n",
       "      <td>https://rutube.ru/video/ed11140b6e776891aa92c4...</td>\n",
       "      <td>https://rutube.ru/video/51b377e74c82fa13252059...</td>\n",
       "      <td>https://rutube.ru/video/3fea6bd428e02c38e32dd7...</td>\n",
       "      <td>https://rutube.ru/video/44304ec49790b2c98d05f4...</td>\n",
       "      <td>https://rutube.ru/video/36f8736e9095805c852b20...</td>\n",
       "      <td>https://rutube.ru/video/f19ad1c071d7dd18575af7...</td>\n",
       "      <td>https://rutube.ru/video/82a4d82bdfa4669170ade5...</td>\n",
       "      <td>https://rutube.ru/video/85105a8dee2f1fade90e39...</td>\n",
       "      <td>https://rutube.ru/video/527867fac9d91b32d77d7b...</td>\n",
       "      <td>https://rutube.ru/video/ef27cc0068154d708c7c54...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Бизнес</td>\n",
       "      <td>Business</td>\n",
       "      <td>Вадим</td>\n",
       "      <td>https://rutube.ru/video/5b6a2166ff1ba47314baf6...</td>\n",
       "      <td>https://rutube.ru/video/85105a8dee2f1fade90e39...</td>\n",
       "      <td>https://rutube.ru/video/85105a8dee2f1fade90e39...</td>\n",
       "      <td>https://rutube.ru/video/85105a8dee2f1fade90e39...</td>\n",
       "      <td>https://rutube.ru/video/b2b9172b9d4264d11145a9...</td>\n",
       "      <td>https://rutube.ru/video/85105a8dee2f1fade90e39...</td>\n",
       "      <td>https://rutube.ru/video/c1f56ba54b222ae9f7c9b3...</td>\n",
       "      <td>https://rutube.ru/video/ff2a8becb2fa7f5f82bba4...</td>\n",
       "      <td>https://rutube.ru/video/158265763c7782618af6e4...</td>\n",
       "      <td>https://rutube.ru/video/a49a0b07c149af2b4ed4cc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Видеоигры</td>\n",
       "      <td>Video games</td>\n",
       "      <td>Вадим</td>\n",
       "      <td>https://rutube.ru/video/c2c5a9f12842dc688f95c4...</td>\n",
       "      <td>https://rutube.ru/video/75029800c1b279e65ea37b...</td>\n",
       "      <td>https://rutube.ru/video/664e41a9df7197ad439c67...</td>\n",
       "      <td>https://rutube.ru/video/2ecb0a65a836507ea111ee...</td>\n",
       "      <td>https://rutube.ru/video/6bed3415e99727b9a8e8cb...</td>\n",
       "      <td>https://rutube.ru/video/7fe2d08520b032d3f631e3...</td>\n",
       "      <td>https://rutube.ru/video/eb400b42bc6de612a96fc3...</td>\n",
       "      <td>https://rutube.ru/video/25696c40ca62dbb73bad1a...</td>\n",
       "      <td>https://rutube.ru/video/5a02ffbb2b48f403f7c7f8...</td>\n",
       "      <td>https://rutube.ru/video/0acda6bbe6ced9fb7beb07...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  lvl  parent id        name   name (eng) Unnamed: 5  \\\n",
       "0  0.0  1.0        0.0   Авто-мото    Auto-moto      Вадим   \n",
       "1  1.0  1.0        1.0       Аниме        Anime      Вадим   \n",
       "2  2.0  1.0        2.0  Аудиокниги   Audiobooks      Вадим   \n",
       "3  3.0  1.0        3.0      Бизнес     Business      Вадим   \n",
       "4  4.0  1.0        4.0   Видеоигры  Video games      Вадим   \n",
       "\n",
       "                                                url1  \\\n",
       "0  https://rutube.ru/video/77fb221d8c1e75da78bf40...   \n",
       "1  https://rutube.ru/video/71bae0ad0ee61339fc8fae...   \n",
       "2  https://rutube.ru/video/ed11140b6e776891aa92c4...   \n",
       "3  https://rutube.ru/video/5b6a2166ff1ba47314baf6...   \n",
       "4  https://rutube.ru/video/c2c5a9f12842dc688f95c4...   \n",
       "\n",
       "                                                url2  \\\n",
       "0  https://rutube.ru/video/a3a5e23a53a4f295210d79...   \n",
       "1  https://rutube.ru/video/85105a8dee2f1fade90e39...   \n",
       "2  https://rutube.ru/video/51b377e74c82fa13252059...   \n",
       "3  https://rutube.ru/video/85105a8dee2f1fade90e39...   \n",
       "4  https://rutube.ru/video/75029800c1b279e65ea37b...   \n",
       "\n",
       "                                                url3  \\\n",
       "0  https://rutube.ru/shorts/f508b3c1b7efbd72a710f...   \n",
       "1  https://rutube.ru/video/4313978b579b72bb9a19fc...   \n",
       "2  https://rutube.ru/video/3fea6bd428e02c38e32dd7...   \n",
       "3  https://rutube.ru/video/85105a8dee2f1fade90e39...   \n",
       "4  https://rutube.ru/video/664e41a9df7197ad439c67...   \n",
       "\n",
       "                                                url4  \\\n",
       "0  https://rutube.ru/video/b2784e7803b339ec734609...   \n",
       "1  https://rutube.ru/video/09577d13d97015440875a8...   \n",
       "2  https://rutube.ru/video/44304ec49790b2c98d05f4...   \n",
       "3  https://rutube.ru/video/85105a8dee2f1fade90e39...   \n",
       "4  https://rutube.ru/video/2ecb0a65a836507ea111ee...   \n",
       "\n",
       "                                                url5  \\\n",
       "0  https://rutube.ru/video/671040092dd0f2f25da6ce...   \n",
       "1  https://rutube.ru/video/d9229991afcc92464e04d3...   \n",
       "2  https://rutube.ru/video/36f8736e9095805c852b20...   \n",
       "3  https://rutube.ru/video/b2b9172b9d4264d11145a9...   \n",
       "4  https://rutube.ru/video/6bed3415e99727b9a8e8cb...   \n",
       "\n",
       "                                                url6  \\\n",
       "0  https://rutube.ru/video/a4f693322a0b3a31d2f3e4...   \n",
       "1  https://rutube.ru/video/6c96553552c8f88866e5f2...   \n",
       "2  https://rutube.ru/video/f19ad1c071d7dd18575af7...   \n",
       "3  https://rutube.ru/video/85105a8dee2f1fade90e39...   \n",
       "4  https://rutube.ru/video/7fe2d08520b032d3f631e3...   \n",
       "\n",
       "                                                url7  \\\n",
       "0  https://rutube.ru/video/460d0196cbfe0a76eb3c01...   \n",
       "1  https://rutube.ru/video/ade8f3276e6312e86a9ce5...   \n",
       "2  https://rutube.ru/video/82a4d82bdfa4669170ade5...   \n",
       "3  https://rutube.ru/video/c1f56ba54b222ae9f7c9b3...   \n",
       "4  https://rutube.ru/video/eb400b42bc6de612a96fc3...   \n",
       "\n",
       "                                                url8  \\\n",
       "0  https://rutube.ru/video/d83bd4cda356071372e701...   \n",
       "1  https://rutube.ru/video/5e6a566bea497140f58bc0...   \n",
       "2  https://rutube.ru/video/85105a8dee2f1fade90e39...   \n",
       "3  https://rutube.ru/video/ff2a8becb2fa7f5f82bba4...   \n",
       "4  https://rutube.ru/video/25696c40ca62dbb73bad1a...   \n",
       "\n",
       "                                                url9  \\\n",
       "0  https://rutube.ru/video/0d6f5d3d204b3bcc24d62f...   \n",
       "1  https://rutube.ru/video/2e6c5019183bea0a449474...   \n",
       "2  https://rutube.ru/video/527867fac9d91b32d77d7b...   \n",
       "3  https://rutube.ru/video/158265763c7782618af6e4...   \n",
       "4  https://rutube.ru/video/5a02ffbb2b48f403f7c7f8...   \n",
       "\n",
       "                                               url10 Unnamed: 16 Unnamed: 17  \\\n",
       "0  https://rutube.ru/video/f1869f4b1e664a7886ff86...         NaN         NaN   \n",
       "1  https://rutube.ru/video/b7de1ae017b850e5f20152...         NaN         NaN   \n",
       "2  https://rutube.ru/video/ef27cc0068154d708c7c54...         NaN         NaN   \n",
       "3  https://rutube.ru/video/a49a0b07c149af2b4ed4cc...         NaN         NaN   \n",
       "4  https://rutube.ru/video/0acda6bbe6ced9fb7beb07...         NaN         NaN   \n",
       "\n",
       "  Unnamed: 18  \n",
       "0         NaN  \n",
       "1         NaN  \n",
       "2         NaN  \n",
       "3         NaN  \n",
       "4         NaN  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('Categories.xlsx')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8cb72727-b68f-4220-97ad-11dd446a6f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "acdcf3c7-3883-4afa-b6cc-ee24ae8b73c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lvl</th>\n",
       "      <th>parent id</th>\n",
       "      <th>name</th>\n",
       "      <th>name (eng)</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>url1</th>\n",
       "      <th>url2</th>\n",
       "      <th>url3</th>\n",
       "      <th>url4</th>\n",
       "      <th>url5</th>\n",
       "      <th>url6</th>\n",
       "      <th>url7</th>\n",
       "      <th>url8</th>\n",
       "      <th>url9</th>\n",
       "      <th>url10</th>\n",
       "      <th>Unnamed: 16</th>\n",
       "      <th>Unnamed: 17</th>\n",
       "      <th>Unnamed: 18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Авто-мото</td>\n",
       "      <td>Auto-moto</td>\n",
       "      <td>Вадим</td>\n",
       "      <td>https://rutube.ru/video/77fb221d8c1e75da78bf40...</td>\n",
       "      <td>https://rutube.ru/video/a3a5e23a53a4f295210d79...</td>\n",
       "      <td>https://rutube.ru/shorts/f508b3c1b7efbd72a710f...</td>\n",
       "      <td>https://rutube.ru/video/b2784e7803b339ec734609...</td>\n",
       "      <td>https://rutube.ru/video/671040092dd0f2f25da6ce...</td>\n",
       "      <td>https://rutube.ru/video/a4f693322a0b3a31d2f3e4...</td>\n",
       "      <td>https://rutube.ru/video/460d0196cbfe0a76eb3c01...</td>\n",
       "      <td>https://rutube.ru/video/d83bd4cda356071372e701...</td>\n",
       "      <td>https://rutube.ru/video/0d6f5d3d204b3bcc24d62f...</td>\n",
       "      <td>https://rutube.ru/video/f1869f4b1e664a7886ff86...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Аниме</td>\n",
       "      <td>Anime</td>\n",
       "      <td>Вадим</td>\n",
       "      <td>https://rutube.ru/video/71bae0ad0ee61339fc8fae...</td>\n",
       "      <td>https://rutube.ru/video/85105a8dee2f1fade90e39...</td>\n",
       "      <td>https://rutube.ru/video/4313978b579b72bb9a19fc...</td>\n",
       "      <td>https://rutube.ru/video/09577d13d97015440875a8...</td>\n",
       "      <td>https://rutube.ru/video/d9229991afcc92464e04d3...</td>\n",
       "      <td>https://rutube.ru/video/6c96553552c8f88866e5f2...</td>\n",
       "      <td>https://rutube.ru/video/ade8f3276e6312e86a9ce5...</td>\n",
       "      <td>https://rutube.ru/video/5e6a566bea497140f58bc0...</td>\n",
       "      <td>https://rutube.ru/video/2e6c5019183bea0a449474...</td>\n",
       "      <td>https://rutube.ru/video/b7de1ae017b850e5f20152...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Аудиокниги</td>\n",
       "      <td>Audiobooks</td>\n",
       "      <td>Вадим</td>\n",
       "      <td>https://rutube.ru/video/ed11140b6e776891aa92c4...</td>\n",
       "      <td>https://rutube.ru/video/51b377e74c82fa13252059...</td>\n",
       "      <td>https://rutube.ru/video/3fea6bd428e02c38e32dd7...</td>\n",
       "      <td>https://rutube.ru/video/44304ec49790b2c98d05f4...</td>\n",
       "      <td>https://rutube.ru/video/36f8736e9095805c852b20...</td>\n",
       "      <td>https://rutube.ru/video/f19ad1c071d7dd18575af7...</td>\n",
       "      <td>https://rutube.ru/video/82a4d82bdfa4669170ade5...</td>\n",
       "      <td>https://rutube.ru/video/85105a8dee2f1fade90e39...</td>\n",
       "      <td>https://rutube.ru/video/527867fac9d91b32d77d7b...</td>\n",
       "      <td>https://rutube.ru/video/ef27cc0068154d708c7c54...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Бизнес</td>\n",
       "      <td>Business</td>\n",
       "      <td>Вадим</td>\n",
       "      <td>https://rutube.ru/video/5b6a2166ff1ba47314baf6...</td>\n",
       "      <td>https://rutube.ru/video/85105a8dee2f1fade90e39...</td>\n",
       "      <td>https://rutube.ru/video/85105a8dee2f1fade90e39...</td>\n",
       "      <td>https://rutube.ru/video/85105a8dee2f1fade90e39...</td>\n",
       "      <td>https://rutube.ru/video/b2b9172b9d4264d11145a9...</td>\n",
       "      <td>https://rutube.ru/video/85105a8dee2f1fade90e39...</td>\n",
       "      <td>https://rutube.ru/video/c1f56ba54b222ae9f7c9b3...</td>\n",
       "      <td>https://rutube.ru/video/ff2a8becb2fa7f5f82bba4...</td>\n",
       "      <td>https://rutube.ru/video/158265763c7782618af6e4...</td>\n",
       "      <td>https://rutube.ru/video/a49a0b07c149af2b4ed4cc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Видеоигры</td>\n",
       "      <td>Video games</td>\n",
       "      <td>Вадим</td>\n",
       "      <td>https://rutube.ru/video/c2c5a9f12842dc688f95c4...</td>\n",
       "      <td>https://rutube.ru/video/75029800c1b279e65ea37b...</td>\n",
       "      <td>https://rutube.ru/video/664e41a9df7197ad439c67...</td>\n",
       "      <td>https://rutube.ru/video/2ecb0a65a836507ea111ee...</td>\n",
       "      <td>https://rutube.ru/video/6bed3415e99727b9a8e8cb...</td>\n",
       "      <td>https://rutube.ru/video/7fe2d08520b032d3f631e3...</td>\n",
       "      <td>https://rutube.ru/video/eb400b42bc6de612a96fc3...</td>\n",
       "      <td>https://rutube.ru/video/25696c40ca62dbb73bad1a...</td>\n",
       "      <td>https://rutube.ru/video/5a02ffbb2b48f403f7c7f8...</td>\n",
       "      <td>https://rutube.ru/video/0acda6bbe6ced9fb7beb07...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>рэп</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Электроника</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ретро</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>226</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Рок</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Альтернативная</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>228 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  lvl  parent id            name   name (eng) Unnamed: 5  \\\n",
       "0    0.0  1.0        0.0       Авто-мото    Auto-moto      Вадим   \n",
       "1    1.0  1.0        1.0           Аниме        Anime      Вадим   \n",
       "2    2.0  1.0        2.0      Аудиокниги   Audiobooks      Вадим   \n",
       "3    3.0  1.0        3.0          Бизнес     Business      Вадим   \n",
       "4    4.0  1.0        4.0       Видеоигры  Video games      Вадим   \n",
       "..   ...  ...        ...             ...          ...        ...   \n",
       "223  NaN  NaN        NaN             рэп          NaN        NaN   \n",
       "224  NaN  NaN        NaN     Электроника          NaN        NaN   \n",
       "225  NaN  NaN        NaN           Ретро          NaN        NaN   \n",
       "226  NaN  NaN        NaN             Рок          NaN        NaN   \n",
       "227  NaN  NaN        NaN  Альтернативная          NaN        NaN   \n",
       "\n",
       "                                                  url1  \\\n",
       "0    https://rutube.ru/video/77fb221d8c1e75da78bf40...   \n",
       "1    https://rutube.ru/video/71bae0ad0ee61339fc8fae...   \n",
       "2    https://rutube.ru/video/ed11140b6e776891aa92c4...   \n",
       "3    https://rutube.ru/video/5b6a2166ff1ba47314baf6...   \n",
       "4    https://rutube.ru/video/c2c5a9f12842dc688f95c4...   \n",
       "..                                                 ...   \n",
       "223                                                NaN   \n",
       "224                                                NaN   \n",
       "225                                                NaN   \n",
       "226                                                NaN   \n",
       "227                                                NaN   \n",
       "\n",
       "                                                  url2  \\\n",
       "0    https://rutube.ru/video/a3a5e23a53a4f295210d79...   \n",
       "1    https://rutube.ru/video/85105a8dee2f1fade90e39...   \n",
       "2    https://rutube.ru/video/51b377e74c82fa13252059...   \n",
       "3    https://rutube.ru/video/85105a8dee2f1fade90e39...   \n",
       "4    https://rutube.ru/video/75029800c1b279e65ea37b...   \n",
       "..                                                 ...   \n",
       "223                                                NaN   \n",
       "224                                                NaN   \n",
       "225                                                NaN   \n",
       "226                                                NaN   \n",
       "227                                                NaN   \n",
       "\n",
       "                                                  url3  \\\n",
       "0    https://rutube.ru/shorts/f508b3c1b7efbd72a710f...   \n",
       "1    https://rutube.ru/video/4313978b579b72bb9a19fc...   \n",
       "2    https://rutube.ru/video/3fea6bd428e02c38e32dd7...   \n",
       "3    https://rutube.ru/video/85105a8dee2f1fade90e39...   \n",
       "4    https://rutube.ru/video/664e41a9df7197ad439c67...   \n",
       "..                                                 ...   \n",
       "223                                                NaN   \n",
       "224                                                NaN   \n",
       "225                                                NaN   \n",
       "226                                                NaN   \n",
       "227                                                NaN   \n",
       "\n",
       "                                                  url4  \\\n",
       "0    https://rutube.ru/video/b2784e7803b339ec734609...   \n",
       "1    https://rutube.ru/video/09577d13d97015440875a8...   \n",
       "2    https://rutube.ru/video/44304ec49790b2c98d05f4...   \n",
       "3    https://rutube.ru/video/85105a8dee2f1fade90e39...   \n",
       "4    https://rutube.ru/video/2ecb0a65a836507ea111ee...   \n",
       "..                                                 ...   \n",
       "223                                                NaN   \n",
       "224                                                NaN   \n",
       "225                                                NaN   \n",
       "226                                                NaN   \n",
       "227                                                NaN   \n",
       "\n",
       "                                                  url5  \\\n",
       "0    https://rutube.ru/video/671040092dd0f2f25da6ce...   \n",
       "1    https://rutube.ru/video/d9229991afcc92464e04d3...   \n",
       "2    https://rutube.ru/video/36f8736e9095805c852b20...   \n",
       "3    https://rutube.ru/video/b2b9172b9d4264d11145a9...   \n",
       "4    https://rutube.ru/video/6bed3415e99727b9a8e8cb...   \n",
       "..                                                 ...   \n",
       "223                                                NaN   \n",
       "224                                                NaN   \n",
       "225                                                NaN   \n",
       "226                                                NaN   \n",
       "227                                                NaN   \n",
       "\n",
       "                                                  url6  \\\n",
       "0    https://rutube.ru/video/a4f693322a0b3a31d2f3e4...   \n",
       "1    https://rutube.ru/video/6c96553552c8f88866e5f2...   \n",
       "2    https://rutube.ru/video/f19ad1c071d7dd18575af7...   \n",
       "3    https://rutube.ru/video/85105a8dee2f1fade90e39...   \n",
       "4    https://rutube.ru/video/7fe2d08520b032d3f631e3...   \n",
       "..                                                 ...   \n",
       "223                                                NaN   \n",
       "224                                                NaN   \n",
       "225                                                NaN   \n",
       "226                                                NaN   \n",
       "227                                                NaN   \n",
       "\n",
       "                                                  url7  \\\n",
       "0    https://rutube.ru/video/460d0196cbfe0a76eb3c01...   \n",
       "1    https://rutube.ru/video/ade8f3276e6312e86a9ce5...   \n",
       "2    https://rutube.ru/video/82a4d82bdfa4669170ade5...   \n",
       "3    https://rutube.ru/video/c1f56ba54b222ae9f7c9b3...   \n",
       "4    https://rutube.ru/video/eb400b42bc6de612a96fc3...   \n",
       "..                                                 ...   \n",
       "223                                                NaN   \n",
       "224                                                NaN   \n",
       "225                                                NaN   \n",
       "226                                                NaN   \n",
       "227                                                NaN   \n",
       "\n",
       "                                                  url8  \\\n",
       "0    https://rutube.ru/video/d83bd4cda356071372e701...   \n",
       "1    https://rutube.ru/video/5e6a566bea497140f58bc0...   \n",
       "2    https://rutube.ru/video/85105a8dee2f1fade90e39...   \n",
       "3    https://rutube.ru/video/ff2a8becb2fa7f5f82bba4...   \n",
       "4    https://rutube.ru/video/25696c40ca62dbb73bad1a...   \n",
       "..                                                 ...   \n",
       "223                                                NaN   \n",
       "224                                                NaN   \n",
       "225                                                NaN   \n",
       "226                                                NaN   \n",
       "227                                                NaN   \n",
       "\n",
       "                                                  url9  \\\n",
       "0    https://rutube.ru/video/0d6f5d3d204b3bcc24d62f...   \n",
       "1    https://rutube.ru/video/2e6c5019183bea0a449474...   \n",
       "2    https://rutube.ru/video/527867fac9d91b32d77d7b...   \n",
       "3    https://rutube.ru/video/158265763c7782618af6e4...   \n",
       "4    https://rutube.ru/video/5a02ffbb2b48f403f7c7f8...   \n",
       "..                                                 ...   \n",
       "223                                                NaN   \n",
       "224                                                NaN   \n",
       "225                                                NaN   \n",
       "226                                                NaN   \n",
       "227                                                NaN   \n",
       "\n",
       "                                                 url10 Unnamed: 16  \\\n",
       "0    https://rutube.ru/video/f1869f4b1e664a7886ff86...         NaN   \n",
       "1    https://rutube.ru/video/b7de1ae017b850e5f20152...         NaN   \n",
       "2    https://rutube.ru/video/ef27cc0068154d708c7c54...         NaN   \n",
       "3    https://rutube.ru/video/a49a0b07c149af2b4ed4cc...         NaN   \n",
       "4    https://rutube.ru/video/0acda6bbe6ced9fb7beb07...         NaN   \n",
       "..                                                 ...         ...   \n",
       "223                                                NaN         NaN   \n",
       "224                                                NaN         NaN   \n",
       "225                                                NaN         NaN   \n",
       "226                                                NaN         NaN   \n",
       "227                                                NaN         NaN   \n",
       "\n",
       "    Unnamed: 17 Unnamed: 18  \n",
       "0           NaN         NaN  \n",
       "1           NaN         NaN  \n",
       "2           NaN         NaN  \n",
       "3           NaN         NaN  \n",
       "4           NaN         NaN  \n",
       "..          ...         ...  \n",
       "223         NaN         NaN  \n",
       "224         NaN         NaN  \n",
       "225         NaN         NaN  \n",
       "226         NaN         NaN  \n",
       "227         NaN         NaN  \n",
       "\n",
       "[228 rows x 19 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.iloc[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3b5fbfca-c872-4f32-823b-7ee3605d204f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_rutube_video(video_url, output_path='.', n_minutes=10):\n",
    "    # Options for yt-dlp\n",
    "    end_time = n_minutes * 60\n",
    "    \n",
    "    ydl_opts = {\n",
    "        'format': 'best[height<=360]',  # Download the best available quality\n",
    "        'outtmpl': f'{output_path}/%(title)s.%(ext)s',  # Output file template\n",
    "        'download-sections': f'*0-{end_time}',\n",
    "        'force_keyframes_at_cuts': True, \n",
    "    }\n",
    "\n",
    "    with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([video_url])\n",
    "\n",
    "\n",
    "df = pd.read_excel('Categories.xlsx')\n",
    "df.head()\n",
    "\n",
    "df.drop(columns=['Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18'], inplace=True)\n",
    "df.drop(index=df.index[df.id.isna()], inplace=True)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    category_id = row['id']\n",
    "    category_name = row['name (eng)']\n",
    "\n",
    "    if category_id <= 5:\n",
    "        continue\n",
    "    \n",
    "    # Create a folder named with the category ID and name\n",
    "    folder_name = f\"data/{category_id}_{category_name.lower()}\"\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    \n",
    "    # Download videos from all URL columns\n",
    "    for i in range(1, 11):  # Assuming there are up to 10 URLs (url1 to url10)\n",
    "        url_column = f'url{i}'\n",
    "        if pd.notna(row.get(url_column)):  # Check if URL exists\n",
    "            url = row.get(url_column)\n",
    "            print(f\"Downloading video from {url} into folder {folder_name}\")\n",
    "\n",
    "            try:\n",
    "                download_rutube_video(url, folder_name)\n",
    "            except Exception as e:\n",
    "                print(f'Video {i} from category {category_id}. {category_name} was not downloaded')\n",
    "                continue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1b9d55-ce98-4eaf-87ad-d2d50cca35b6",
   "metadata": {},
   "source": [
    "Check connection to s3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6dee3b86-cde8-45ca-91b5-4c62a41f3040",
   "metadata": {},
   "outputs": [],
   "source": [
    "from minio import Minio\n",
    "\n",
    "client = Minio(\n",
    "    endpoint=\"storage.yandexcloud.net\",\n",
    "    access_key=\"YCAJESQqZUja9X-F1glArEPSY\",\n",
    "    secret_key=\"YCP6M_QUdKUF1XBlgz_hOWAlTkcMbnEUyLG5hsQv\",\n",
    ")\n",
    "\n",
    "bucket = \"rutube-tagging\"\n",
    "\n",
    "\n",
    "def upload_file_to_s3(local_file_path, s3_file_name, bucket_name=bucket_name):\n",
    "    \"\"\"\n",
    "    Upload a file from local path to the S3 bucket.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Upload file\n",
    "        client.fput_object(\n",
    "            bucket_name, s3_file_name, local_file_path\n",
    "        )\n",
    "        print(f\"File '{local_file_path}' uploaded to bucket '{bucket_name}' as '{s3_file_name}'.\")\n",
    "    except S3Error as e:\n",
    "        print(f\"Error uploading file to S3: {e}\")\n",
    "\n",
    "\n",
    "def download_file_from_s3(s3_file_name, local_file_path, bucket_name=bucket_name):\n",
    "    \"\"\"\n",
    "    Download a file from the S3 bucket to local path.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Download file\n",
    "        client.fget_object(\n",
    "            bucket_name, s3_file_name, local_file_path\n",
    "        )\n",
    "        print(f\"File '{s3_file_name}' downloaded from bucket '{bucket_name}' to '{local_file_path}'.\")\n",
    "    except S3Error as e:\n",
    "        print(f\"Error downloading file from S3: {e}\")\n",
    "\n",
    "\n",
    "def list_files_in_bucket(bucket_name=bucket_name):\n",
    "    \"\"\"\n",
    "    List all files in the S3 bucket.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        objects = client.list_objects(bucket_name)\n",
    "        for obj in objects:\n",
    "            print(obj.object_name)\n",
    "    except S3Error as e:\n",
    "        print(f\"Error listing objects in bucket: {e}\")\n",
    "\n",
    "# Examples\n",
    "# download_file_from_s3(\"file_on_s3.txt\", \"path/to/local/file.txt\")\n",
    "# upload_file_to_s3(\"path/to/local/file.txt\", \"file_on_s3.txt\")\n",
    "# list_files_in_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "c7a4a547-435e-4a82-8a94-8d988834c766",
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_k_accuracy(target: np.ndarray, preds: np.ndarray, k: int = 10) -> float:\n",
    "    numer = 0\n",
    "    denom = target.size\n",
    "    \n",
    "    for label, labels_set in zip(target, preds):\n",
    "        if label in labels_set[:k]:\n",
    "            numer += 1\n",
    "\n",
    "    return numer * 1.0 / denom\n",
    "\n",
    "def string_to_numpy(tensor_string):\n",
    "    tensor_string = tensor_string.replace('tensor(', '').rstrip(')')\n",
    "    tensor_data = ast.literal_eval(tensor_string)\n",
    "    tensor = torch.tensor(tensor_data)\n",
    "    \n",
    "    return tensor\n",
    "\n",
    "def string_to_numpy(tensor_string):\n",
    "    tensor_string = tensor_string.replace('tensor(', '').rstrip(')')\n",
    "    tensor_data = ast.literal_eval(tensor_string)\n",
    "    tensor_numpied = torch.tensor(tensor_data).numpy()\n",
    "    \n",
    "    return tensor_numpied\n",
    "\n",
    "label_data = [\n",
    "    (0, 'Авто-мото'),\n",
    "    (1, 'Аниме'),\n",
    "    (2, 'Аудиокниги'),\n",
    "    (3, 'Бизнес'),\n",
    "    (4, 'Видеоигры'),\n",
    "    (5, 'Интервью'),\n",
    "    (6, 'Искусство'),\n",
    "    (7, 'Кино'),\n",
    "    (8, 'Красота'),\n",
    "    (9, 'Кулинария'),\n",
    "    (10, 'Лайфхаки'),\n",
    "    (11, 'Музыка'),\n",
    "    (12, 'Мультфильмы'),\n",
    "    (13, 'Новости'),\n",
    "    (14, 'Обучение'),\n",
    "    (15, 'Охота и рыбалка'),\n",
    "    (16, 'Политика'),\n",
    "    (17, 'Психология'),\n",
    "    (18, 'Путешествия'),\n",
    "    (19, 'Сериалы'),\n",
    "    (20, 'Спорт'),\n",
    "    (22, 'Юмор'),\n",
    "    (25, 'Лайфстайл'),\n",
    "    (26, 'Недвижимость'),\n",
    "    (27, 'Здоровье'),\n",
    "    (28, 'Природа'),\n",
    "    (29, 'Дизайн'),\n",
    "    (30, 'Техника и оборудование'),\n",
    "    (31, 'Бизнес и предпринимательство'),\n",
    "    (32, 'Культура'),\n",
    "    (33, 'Религия'),\n",
    "    (34, 'Строительство и ремонт'),\n",
    "    (35, 'Сад и огород'),\n",
    "    (36, 'Еда'),\n",
    "    (37, 'Развлечения'),\n",
    "    (38, 'Эзотерика'),\n",
    "    (39, 'Наука'),\n",
    "    (40, 'Аудио'),\n",
    "    (41, 'Технологии и интернет'),\n",
    "    (42, 'Телепередачи'),\n",
    "    (43, 'Детям'),\n",
    "    (44, 'Хобби'),\n",
    "    (45, 'Разное'),\n",
    "    (46, 'Животные'),\n",
    "    (47, 'Новости и СМИ'),\n",
    "    (48, 'Фильмы'),\n",
    "    (49, 'Блогеры')\n",
    "]\n",
    "\n",
    "clip_df = pd.read_csv('data/embeddings/x-clip-v2.csv')\n",
    "\n",
    "label_df = pd.DataFrame(label_data, columns=['tag_id', 'tag'])\n",
    "tag_id_to_index = dict(zip(label_df.tag_id, label_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7336b0d2-2203-46bf-b63f-d6404aa3f080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 accuracy: 3.9603960396039604\n",
      "Top 5 accuracy: 6.9306930693069315\n",
      "Top 10 accuracy: 10.891089108910892\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(404, 47)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip_id_label = clip_df.label.apply(lambda x: tag_id_to_index[x]).values\n",
    "top_n_predictions = np.vstack(clip_df.probs.apply(lambda x: np.argsort(string_to_numpy(x)).mean(axis=0)[::-1]))\n",
    "\n",
    "print('Top 1 accuracy:', top_k_accuracy(clip_id_label, top_n_predictions, 1) * 100)\n",
    "print('Top 5 accuracy:', top_k_accuracy(clip_id_label, top_n_predictions, 5) * 100)\n",
    "print('Top 10 accuracy:', top_k_accuracy(clip_id_label, top_n_predictions, 10) * 100)\n",
    "\n",
    "top_n_predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1a79d525-d356-4382-b24e-13b1cae912ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 accuracy: 8.16831683168317\n",
      "Top 5 accuracy: 19.554455445544555\n",
      "Top 10 accuracy: 32.17821782178218\n"
     ]
    }
   ],
   "source": [
    "clip_id_label = clip_df.label.apply(lambda x: tag_id_to_index[x]).values\n",
    "top_n_predictions = np.vstack(clip_df.probs.apply(lambda x: np.argsort(string_to_numpy(x))[0, :][::-1]))\n",
    "\n",
    "print('Top 1 accuracy:', top_k_accuracy(clip_id_label, top_n_predictions, 1) * 100)\n",
    "print('Top 5 accuracy:', top_k_accuracy(clip_id_label, top_n_predictions, 5) * 100)\n",
    "print('Top 10 accuracy:', top_k_accuracy(clip_id_label, top_n_predictions, 10) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4a4414e1-02e8-4e8b-9a65-88debda57a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 accuracy: 9.158415841584159\n",
      "Top 5 accuracy: 20.049504950495052\n",
      "Top 10 accuracy: 31.18811881188119\n"
     ]
    }
   ],
   "source": [
    "clip_id_label = clip_df.label.apply(lambda x: tag_id_to_index[x]).values\n",
    "top_n_predictions = np.vstack(clip_df.probs.apply(lambda x: np.argsort(string_to_numpy(x))[1, :][::-1]))\n",
    "\n",
    "print('Top 1 accuracy:', top_k_accuracy(clip_id_label, top_n_predictions, 1) * 100)\n",
    "print('Top 5 accuracy:', top_k_accuracy(clip_id_label, top_n_predictions, 5) * 100)\n",
    "print('Top 10 accuracy:', top_k_accuracy(clip_id_label, top_n_predictions, 10) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "832b991f-c0bb-4be6-a06c-a16f57b3d7df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 accuracy: 5.445544554455446\n",
      "Top 5 accuracy: 20.049504950495052\n",
      "Top 10 accuracy: 30.198019801980198\n"
     ]
    }
   ],
   "source": [
    "clip_id_label = clip_df.label.apply(lambda x: tag_id_to_index[x]).values\n",
    "top_n_predictions = np.vstack(clip_df.probs.apply(lambda x: np.argsort(string_to_numpy(x))[2, :][::-1]))\n",
    "\n",
    "print('Top 1 accuracy:', top_k_accuracy(clip_id_label, top_n_predictions, 1) * 100)\n",
    "print('Top 5 accuracy:', top_k_accuracy(clip_id_label, top_n_predictions, 5) * 100)\n",
    "print('Top 10 accuracy:', top_k_accuracy(clip_id_label, top_n_predictions, 10) * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
