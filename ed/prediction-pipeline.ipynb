{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95f80c2b-fbfe-4a7b-9f1f-f2651df49a1b",
   "metadata": {},
   "source": [
    "## Импорты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75003a31-433f-4df1-a4c5-5a6cf0bf2ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "\n",
    "import yt_dlp\n",
    "import subprocess\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import gc\n",
    "import json\n",
    "import locale\n",
    "import re\n",
    "import tqdm.notebook as tqdm\n",
    "from urllib.parse import urlparse\n",
    "import requests\n",
    "import math\n",
    "import random\n",
    "\n",
    "import av\n",
    "from huggingface_hub import hf_hub_download\n",
    "from typing import Callable\n",
    "\n",
    "from transformers import VivitImageProcessor, VivitModel\n",
    "from transformers import AutoImageProcessor, VideoMAEModel\n",
    "from transformers import TimesformerConfig, TimesformerModel\n",
    "from transformers import XCLIPProcessor, XCLIPModel\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor\n",
    "from transformers import Wav2Vec2ForCTC, Wav2Vec2Processor\n",
    "from transformers import BitsAndBytesConfig, LlavaNextVideoForConditionalGeneration, LlavaNextVideoProcessor\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "import librosa\n",
    "from moviepy.editor import VideoFileClip\n",
    "import ast\n",
    "import openunmix\n",
    "\n",
    "from minio import Minio\n",
    "from minio.error import S3Error\n",
    "\n",
    "import hydra\n",
    "import soundfile as sf\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "import logging\n",
    "from typing import List\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.cross_decomposition import PLSRegression, CCA\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from metric_learn import NCA\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
    "\n",
    "logging.basicConfig(\n",
    "    filename='vivit_inference.log',\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0fef6d-d90a-48aa-8da8-df5212c4ee05",
   "metadata": {},
   "source": [
    "## Вспомогательные объекты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "323c1d0a-d99a-4cf9-928a-01cff261e88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingStorage:\n",
    "    def __init__(self, labels=None, filenames=None, embeddings=None):\n",
    "        \"\"\"\n",
    "        Initialize the EmbeddingStorage class.\n",
    "        \n",
    "        Args:\n",
    "            labels (list or np.ndarray): An array of labels for the embeddings.\n",
    "            filenames (list or np.ndarray): An array of filenames associated with the embeddings.\n",
    "            embeddings (np.ndarray): A NumPy array containing all embeddings.\n",
    "        \"\"\"\n",
    "        self.labels = np.array(labels) if labels is not None else np.array([])\n",
    "        self.filenames = np.array(filenames) if filenames is not None else np.array([])\n",
    "        self.embeddings = np.array(embeddings) if embeddings is not None else np.empty((0,))\n",
    "\n",
    "    def add_embedding(self, label, filename, embedding):\n",
    "        \"\"\"\n",
    "        Add a new embedding, along with its label and filename.\n",
    "        \n",
    "        Args:\n",
    "            label (int or str): The label of the embedding.\n",
    "            filename (str): The filename associated with the embedding.\n",
    "            embedding (np.ndarray or torch.Tensor): The embedding to add (can be a NumPy array or Tensor).\n",
    "        \"\"\"\n",
    "        if isinstance(embedding, np.ndarray):\n",
    "            emb_array = embedding\n",
    "        else:\n",
    "            # Convert torch.Tensor to NumPy\n",
    "            emb_array = embedding.cpu().numpy()\n",
    "        \n",
    "        # Append the new data\n",
    "        self.labels = np.append(self.labels, label)\n",
    "        self.filenames = np.append(self.filenames, filename)\n",
    "        \n",
    "        if self.embeddings.size == 0:\n",
    "            self.embeddings = emb_array.reshape(1, -1)\n",
    "        else:\n",
    "            self.embeddings = np.vstack([self.embeddings, emb_array])\n",
    "\n",
    "    def save_to_file(self, file_path):\n",
    "        np.savez(file_path, labels=self.labels, filenames=self.filenames, embeddings=self.embeddings)\n",
    "\n",
    "    @classmethod\n",
    "    def load_from_file(cls, file_path):\n",
    "        data = np.load(file_path, allow_pickle=True)\n",
    "        return cls(labels=data['labels'], filenames=data['filenames'], embeddings=data['embeddings'])\n",
    "\n",
    "    def get_embedding_by_filename(self, filename):\n",
    "        if filename in self.filenames:\n",
    "            idx = np.where(self.filenames == filename)[0][0]\n",
    "            return self.embeddings[idx]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def join_on_videoname(self, other_storage):\n",
    "        # Find common filenames\n",
    "        common_filenames = np.intersect1d(self.filenames, other_storage.filenames)\n",
    "        \n",
    "        # Initialize lists to store merged data\n",
    "        merged_labels = []\n",
    "        merged_filenames = []\n",
    "        merged_embeddings = []\n",
    "        \n",
    "        for filename in common_filenames:\n",
    "            # Get embeddings for the common filename from both storages\n",
    "            idx_self = np.where(self.filenames == filename)[0][0]\n",
    "            idx_other = np.where(other_storage.filenames == filename)[0][0]\n",
    "            \n",
    "            emb_self = self.embeddings[idx_self]\n",
    "            emb_other = other_storage.embeddings[idx_other]\n",
    "            \n",
    "            # Store embeddings as a tuple\n",
    "            merged_embedding = (emb_self, emb_other)\n",
    "            \n",
    "            # Get the label from the first storage (could be changed based on use case)\n",
    "            merged_label = self.labels[idx_self]\n",
    "            \n",
    "            # Append to the merged data\n",
    "            merged_labels.append(merged_label)\n",
    "            merged_filenames.append(filename)\n",
    "            merged_embeddings.append(merged_embedding)\n",
    "        \n",
    "        # Convert lists to numpy arrays\n",
    "        merged_labels = np.array(merged_labels)\n",
    "        merged_filenames = np.array(merged_filenames)\n",
    "        merged_embeddings = np.array(merged_embeddings, dtype=object)\n",
    "        \n",
    "        # Return a new EmbeddingStorage instance with merged data\n",
    "        return EmbeddingStorage(labels=merged_labels, filenames=merged_filenames, embeddings=merged_embeddings)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the number of embeddings stored.\n",
    "        \"\"\"\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieve the label, filename, and embedding by index.\n",
    "        \n",
    "        Args:\n",
    "            idx (int): The index of the embedding to retrieve.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: A tuple containing (label, filename, embedding).\n",
    "        \"\"\"\n",
    "        if idx >= len(self.labels):\n",
    "            raise IndexError(\"Index out of range\")\n",
    "        return self.labels[idx], self.filenames[idx], self.embeddings[idx]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"EmbeddingStorage(labels={len(self.labels)}, filenames={len(self.filenames)}, embeddings_shape={self.embeddings.shape})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ba9d539-8465-4c7b-a0ff-7e7b92303251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou_metric(ground_truth, predictions):\n",
    "    iou =  len(set.intersection(set(ground_truth), set(predictions)))\n",
    "    iou = iou/(len(set(ground_truth).union(set(predictions))))\n",
    "    print(iou, ground_truth, predictions)\n",
    "    return iou\n",
    "\n",
    "def split_tags(tag_list):\n",
    "    final_tag_list = []\n",
    "    for tag in tag_list:\n",
    "        tags = [tag.strip().lower() for tag in tag.split(\":\")]\n",
    "        if len(tags) == 3:\n",
    "            final_tag_list.append(tags[0])\n",
    "            final_tag_list.append(tags[0] + \": \" + tags[1])\n",
    "            final_tag_list.append(tags[0]+ \": \" + tags[1] + \": \" + tags[2])\n",
    "        elif len(tags) == 2:\n",
    "            final_tag_list.append(tags[0])\n",
    "            final_tag_list.append(tags[0] + \": \" + tags[1])\n",
    "        elif len(tags) == 1:\n",
    "            final_tag_list.append(tags[0])\n",
    "        else:\n",
    "            print(\"NOT IMPLEMENTED!!!!\", tag)\n",
    "    return final_tag_list\n",
    "\n",
    "\n",
    "def find_iou_for_sample_submission(pred_submission, true_submission):\n",
    "    ground_truth_df = true_submission\n",
    "    ground_truth_df[\"tags\"] = ground_truth_df[\"tags\"].apply(lambda l: l.split(', '))\n",
    "    ground_truth_df[\"tags_split\"] = ground_truth_df[\"tags\"].apply(lambda l: split_tags(l))\n",
    "\n",
    "    predictions_df = pred_submission\n",
    "    # predictions_df[\"predicted_tags\"] = predictions_df[\"predicted_tags\"].apply(ast.literal_eval)\n",
    "    predictions_df[\"predicted_tags_split\"] = predictions_df[\"predicted_tags\"].apply(lambda l: split_tags(l))\n",
    "    iou=0\n",
    "    counter = 0\n",
    "    for i, row in ground_truth_df.iterrows():\n",
    "        predicted_tags = predictions_df[predictions_df[\"video_id\"]==row[\"video_id\"]][\"predicted_tags_split\"].values[0]\n",
    "        iou_temp=iou_metric(row['tags_split'], predicted_tags)\n",
    "        iou+=iou_temp\n",
    "        counter+=1\n",
    "\n",
    "    return iou/counter\n",
    "\n",
    "\n",
    "def create_tags_to_labels(taxonomy):\n",
    "    tags = {}\n",
    "    for i, row in tqdm.tqdm(taxonomy.iterrows()):\n",
    "        if isinstance(row['Уровень 3 (iab)'], str):\n",
    "            tags[row['Уровень 1 (iab)'].strip().lower()+ \": \"+row['Уровень 2 (iab)'].strip().lower()+\": \"+row['Уровень 3 (iab)'].strip().lower()] = i\n",
    "        elif isinstance(row['Уровень 2 (iab)'], str):\n",
    "            tags[row['Уровень 1 (iab)'].strip().lower()+ \": \"+row['Уровень 2 (iab)'].strip().lower()] = i\n",
    "        elif isinstance(row['Уровень 1 (iab)'], str):\n",
    "            tags[row['Уровень 1 (iab)'].strip().lower()] = i\n",
    "    return tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87ae226-bb66-4290-963f-41fc6704268f",
   "metadata": {},
   "source": [
    "## Get description's embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc939497-f8c6-4645-a06f-70fce73a73cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"train_data_categories.csv\", index_col=0)\n",
    "taxonomy = pd.read_csv(\"IAB_tags.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b4f927fa-28ff-4b32-b6b5-6003d63658f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.422692  , -1.0444894 ,  0.24923438, ..., -0.17118785,\n",
       "        -0.5136193 ,  1.7617834 ],\n",
       "       [-1.1715692 , -1.151326  ,  0.23327589, ...,  0.13894735,\n",
       "        -0.9368831 ,  0.80480146],\n",
       "       [-0.9565279 , -0.4599986 ,  0.59576195, ..., -0.51299   ,\n",
       "        -0.5534946 ,  0.46441787],\n",
       "       ...,\n",
       "       [-0.86119896, -1.0143728 ,  0.04060396, ...,  0.477794  ,\n",
       "        -0.55605567,  1.7086926 ],\n",
       "       [-0.75098073, -1.5116149 ,  0.28733295, ...,  1.100044  ,\n",
       "         0.19477315,  0.7473654 ],\n",
       "       [-0.8942005 , -1.4155393 ,  0.55456275, ...,  0.84573764,\n",
       "        -0.42715627,  0.37667847]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.vstack(encoded_values.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a0107ec-4686-4f94-aa74-753e4e8142fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SentenceTransformer('DeepPavlov/rubert-base-cased-sentence')\n",
    "# model.save_pretrained('models/rubert')\n",
    "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# model = SentenceTransformer('models/rubert/')\n",
    "# model.to(device)\n",
    "# model.eval()\n",
    "# encoded_values = data['description'].apply(lambda l: model.encode(l, convert_to_tensor=True).cpu().numpy())\n",
    "rubert_emb = EmbeddingStorage(filenames=data.index, embeddings=np.vstack(encoded_values.values))\n",
    "rubert_emb.save_to_file('data/new_embeddings/description_emb.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8305fab8-9d16-45ef-8fd7-60336da3d567",
   "metadata": {},
   "source": [
    "## Clear tags data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a2035de-f825-44a6-99da-b84e3133c310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d8ce6745a15412c93abbfb41a659d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tags_to_labels = create_tags_to_labels(taxonomy)\n",
    "labels_to_tags = {v: k for k, v in tags_to_labels.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df42f103-334b-45d6-a3d4-1a68b46d05cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa040e68306943c480867e54bce992ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty list\n",
      "Empty list\n",
      "Empty list\n",
      "Empty list\n"
     ]
    }
   ],
   "source": [
    "def assign_category_ids(data, tags_to_labels):\n",
    "    category_ids = []\n",
    "    \n",
    "    for i, row in tqdm.tqdm(data.iterrows()):\n",
    "        tags = row['tags'].split(', ')  # Split tags by comma\n",
    "        split_tag_list = split_tags(tags)  # Split hierarchical tags\n",
    "\n",
    "        # Convert the tags to category IDs\n",
    "        valid_ids = [tags_to_labels[tag] for tag in split_tag_list if tag in tags_to_labels]\n",
    "\n",
    "        if len(valid_ids) > 0:\n",
    "            # If valid category IDs are found, use all of them\n",
    "            category_ids.append(valid_ids)  # Append the list of valid IDs\n",
    "        else:\n",
    "            # If no valid tags, assign a random category\n",
    "            print(\"Empty list\", )\n",
    "            category_ids.append([random.choice(list(tags_to_labels.values()))])  # Random category from available tags\n",
    "\n",
    "    return category_ids\n",
    "\n",
    "\n",
    "data['category_id'] = assign_category_ids(data, tags_to_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6949ce35-5781-4820-8b2d-882ed1c32998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "video_id\n",
       "9007f33c8347924ffa12f922da2a179d              [398, 406]\n",
       "9012707c45233bd601dead57bc9e2eca    [137, 162, 398, 406]\n",
       "e01d6ebabbc27e323fa1b7c581e9b96a    [398, 403, 398, 404]\n",
       "a00b145242be3ebc3b311455e94917af      [0, 447, 480, 398]\n",
       "b01a682bf4dfcc09f1e8fac5bc18785a              [398, 406]\n",
       "                                            ...         \n",
       "5fe16aa2869667bc1519e32a4c536b26              [398, 403]\n",
       "4ffa5fbb2a410aa841659d8890ae5e3f              [196, 202]\n",
       "3fc81df4bfe121ce2bc33dd581f5efeb                   [447]\n",
       "efe0b4139ef82ec270b9e2fe0216214e      [40, 47, 313, 112]\n",
       "fff1ef66d848bc8987ac5126f05b053b              [313, 344]\n",
       "Name: category_id, Length: 1049, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['category_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0892dbe2-88ec-4d76-8ebb-5e53187c5c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# whisper_emb = EmbeddingStorage.load_from_file('data/new_embeddings/whisper.npz')\n",
    "# rubert_emb = EmbeddingStorage.load_from_file('data/new_embeddings/description_emb.npz')\n",
    "# xclip_emb = EmbeddingStorage.load_from_file('data/new_embeddings/xclip_emb.npz')\n",
    "# xclip_emb.embeddings = xclip_emb.embeddings.mean(axis=1)\n",
    "\n",
    "data['audio_emb'] = [None] * len(data)\n",
    "data['text_emb'] = [None] * len(data)\n",
    "data['video_emb'] = [None] * len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1d478a7e-6ad0-42be-8ec2-b0a885c5ec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "for filename, row in data.iterrows():\n",
    "    data.at[filename, 'video_emb'] = xclip_emb.get_embedding_by_filename(filename + '.mp4')\n",
    "    data.at[filename, 'audio_emb'] = whisper_emb.get_embedding_by_filename(filename + '.mp4')\n",
    "    data.at[filename, 'text_emb'] = rubert_emb.get_embedding_by_filename(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1cc3c4e8-e8ef-41a2-bae1-ead8bf15fae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = np.vstack(data.audio_emb.values)\n",
    "X2 = np.vstack(data.text_emb.values)\n",
    "X3 = np.vstack(data.video_emb.values)\n",
    "Y = data.category_id.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f65331-2c0c-4a1c-865d-755bd0313e57",
   "metadata": {},
   "source": [
    "All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c2b029d7-645e-4ca2-af97-b518db7543d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1...\n",
      "Fold 1 IoU score: 0.5821\n",
      "Training fold 2...\n",
      "Fold 2 IoU score: 0.5749\n",
      "Training fold 3...\n",
      "Fold 3 IoU score: 0.5654\n",
      "Training fold 4...\n",
      "Fold 4 IoU score: 0.5720\n",
      "Training fold 5...\n",
      "Fold 5 IoU score: 0.5589\n",
      "Average IoU score across all 5 folds: 0.5707\n"
     ]
    }
   ],
   "source": [
    "X = np.hstack([X1, X2, X3])  # Concatenate audio, text, and video embeddings\n",
    "\n",
    "# Step 2: Convert Y to a binary matrix using MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y_enc = mlb.fit_transform(Y)  # Y is your category_id, encoded as multilabel\n",
    "\n",
    "# Step 3: Define IoU (Jaccard Similarity) for multilabel classification\n",
    "def calculate_iou(y_true, y_pred):\n",
    "    iou_scores = []\n",
    "    for true_labels, pred_labels in zip(y_true, y_pred):\n",
    "        true_set = set(true_labels)\n",
    "        pred_set = set(pred_labels)\n",
    "        intersection = len(true_set.intersection(pred_set))\n",
    "        union = len(true_set.union(pred_set))\n",
    "        if union == 0:\n",
    "            iou_scores.append(1.0)\n",
    "        else:\n",
    "            iou_scores.append(intersection / union)\n",
    "    return np.mean(iou_scores)\n",
    "\n",
    "# Step 4: Define the cross-validation process\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold = 1\n",
    "iou_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(f\"Training fold {fold}...\")\n",
    "    \n",
    "    # Split the data into training and test sets for this fold\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y_enc[train_index], Y_enc[test_index]\n",
    "    \n",
    "    # KNN classifier for multilabel classification\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    multi_knn = MultiOutputClassifier(knn, n_jobs=-1)\n",
    "    multi_knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predict using the KNN classifier\n",
    "    y_pred_enc = multi_knn.predict(X_test)\n",
    "\n",
    "    # Decode the predictions back to original multilabel format\n",
    "    y_pred = mlb.inverse_transform(y_pred_enc)\n",
    "    y_test_decoded = mlb.inverse_transform(y_test)\n",
    "\n",
    "    # Calculate IoU for this fold\n",
    "    fold_iou_score = calculate_iou(y_test_decoded, y_pred)\n",
    "    iou_scores.append(fold_iou_score)\n",
    "    \n",
    "    print(f\"Fold {fold} IoU score: {fold_iou_score:.4f}\")\n",
    "    fold += 1\n",
    "\n",
    "# Step 5: Calculate the average IoU across all folds\n",
    "average_iou = np.mean(iou_scores)\n",
    "print(f\"Average IoU score across all 5 folds: {average_iou:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547aeb78-6b03-487f-ba25-ae0331c14651",
   "metadata": {},
   "source": [
    "Audio and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b5a9c101-c7e7-48f0-8123-18b3dbd9d052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1...\n",
      "Fold 1 IoU score: 0.5821\n",
      "Training fold 2...\n",
      "Fold 2 IoU score: 0.5761\n",
      "Training fold 3...\n",
      "Fold 3 IoU score: 0.5654\n",
      "Training fold 4...\n",
      "Fold 4 IoU score: 0.5720\n",
      "Training fold 5...\n",
      "Fold 5 IoU score: 0.5589\n",
      "Average IoU score across all 5 folds: 0.5709\n"
     ]
    }
   ],
   "source": [
    "X = np.hstack([X1, X2])  # Concatenate audio, text, and video embeddings\n",
    "\n",
    "# Step 2: Convert Y to a binary matrix using MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y_enc = mlb.fit_transform(Y)  # Y is your category_id, encoded as multilabel\n",
    "\n",
    "# Step 3: Define IoU (Jaccard Similarity) for multilabel classification\n",
    "def calculate_iou(y_true, y_pred):\n",
    "    iou_scores = []\n",
    "    for true_labels, pred_labels in zip(y_true, y_pred):\n",
    "        true_set = set(true_labels)\n",
    "        pred_set = set(pred_labels)\n",
    "        intersection = len(true_set.intersection(pred_set))\n",
    "        union = len(true_set.union(pred_set))\n",
    "        if union == 0:\n",
    "            iou_scores.append(1.0)\n",
    "        else:\n",
    "            iou_scores.append(intersection / union)\n",
    "    return np.mean(iou_scores)\n",
    "\n",
    "# Step 4: Define the cross-validation process\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold = 1\n",
    "iou_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(f\"Training fold {fold}...\")\n",
    "    \n",
    "    # Split the data into training and test sets for this fold\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y_enc[train_index], Y_enc[test_index]\n",
    "    \n",
    "    # KNN classifier for multilabel classification\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    multi_knn = MultiOutputClassifier(knn, n_jobs=-1)\n",
    "    multi_knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predict using the KNN classifier\n",
    "    y_pred_enc = multi_knn.predict(X_test)\n",
    "\n",
    "    # Decode the predictions back to original multilabel format\n",
    "    y_pred = mlb.inverse_transform(y_pred_enc)\n",
    "    y_test_decoded = mlb.inverse_transform(y_test)\n",
    "\n",
    "    # Calculate IoU for this fold\n",
    "    fold_iou_score = calculate_iou(y_test_decoded, y_pred)\n",
    "    iou_scores.append(fold_iou_score)\n",
    "    \n",
    "    print(f\"Fold {fold} IoU score: {fold_iou_score:.4f}\")\n",
    "    fold += 1\n",
    "\n",
    "# Step 5: Calculate the average IoU across all folds\n",
    "average_iou = np.mean(iou_scores)\n",
    "print(f\"Average IoU score across all 5 folds: {average_iou:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2782f3-0129-4dd5-a4df-f7aad58132a7",
   "metadata": {},
   "source": [
    "Video and text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4555a38e-cb68-4162-82ed-b1bcf1a923a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1...\n",
      "Fold 1 IoU score: 0.5785\n",
      "Training fold 2...\n",
      "Fold 2 IoU score: 0.5813\n",
      "Training fold 3...\n",
      "Fold 3 IoU score: 0.5674\n",
      "Training fold 4...\n",
      "Fold 4 IoU score: 0.5722\n",
      "Training fold 5...\n",
      "Fold 5 IoU score: 0.5190\n",
      "Average IoU score across all 5 folds: 0.5637\n"
     ]
    }
   ],
   "source": [
    "X = np.hstack([X2, X3])  # Concatenate audio, text, and video embeddings\n",
    "\n",
    "# Step 2: Convert Y to a binary matrix using MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y_enc = mlb.fit_transform(Y)  # Y is your category_id, encoded as multilabel\n",
    "\n",
    "# Step 3: Define IoU (Jaccard Similarity) for multilabel classification\n",
    "def calculate_iou(y_true, y_pred):\n",
    "    iou_scores = []\n",
    "    for true_labels, pred_labels in zip(y_true, y_pred):\n",
    "        true_set = set(true_labels)\n",
    "        pred_set = set(pred_labels)\n",
    "        intersection = len(true_set.intersection(pred_set))\n",
    "        union = len(true_set.union(pred_set))\n",
    "        if union == 0:\n",
    "            iou_scores.append(1.0)\n",
    "        else:\n",
    "            iou_scores.append(intersection / union)\n",
    "    return np.mean(iou_scores)\n",
    "\n",
    "# Step 4: Define the cross-validation process\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold = 1\n",
    "iou_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(f\"Training fold {fold}...\")\n",
    "    \n",
    "    # Split the data into training and test sets for this fold\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y_enc[train_index], Y_enc[test_index]\n",
    "    \n",
    "    # KNN classifier for multilabel classification\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    multi_knn = MultiOutputClassifier(knn, n_jobs=-1)\n",
    "    multi_knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predict using the KNN classifier\n",
    "    y_pred_enc = multi_knn.predict(X_test)\n",
    "\n",
    "    # Decode the predictions back to original multilabel format\n",
    "    y_pred = mlb.inverse_transform(y_pred_enc)\n",
    "    y_test_decoded = mlb.inverse_transform(y_test)\n",
    "\n",
    "    # Calculate IoU for this fold\n",
    "    fold_iou_score = calculate_iou(y_test_decoded, y_pred)\n",
    "    iou_scores.append(fold_iou_score)\n",
    "    \n",
    "    print(f\"Fold {fold} IoU score: {fold_iou_score:.4f}\")\n",
    "    fold += 1\n",
    "\n",
    "# Step 5: Calculate the average IoU across all folds\n",
    "average_iou = np.mean(iou_scores)\n",
    "print(f\"Average IoU score across all 5 folds: {average_iou:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb7b9ec-d960-4e26-8fb1-430e5c343bc1",
   "metadata": {},
   "source": [
    "Audio and video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f2f0a156-6aa3-4dce-a4f5-b9503ddc1a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1...\n",
      "Fold 1 IoU score: 0.4688\n",
      "Training fold 2...\n",
      "Fold 2 IoU score: 0.5100\n",
      "Training fold 3...\n",
      "Fold 3 IoU score: 0.4698\n",
      "Training fold 4...\n",
      "Fold 4 IoU score: 0.4796\n",
      "Training fold 5...\n",
      "Fold 5 IoU score: 0.4600\n",
      "Average IoU score across all 5 folds: 0.4776\n"
     ]
    }
   ],
   "source": [
    "X = np.hstack([X1, X3])  # Concatenate audio, text, and video embeddings\n",
    "\n",
    "# Step 2: Convert Y to a binary matrix using MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y_enc = mlb.fit_transform(Y)  # Y is your category_id, encoded as multilabel\n",
    "\n",
    "# Step 3: Define IoU (Jaccard Similarity) for multilabel classification\n",
    "def calculate_iou(y_true, y_pred):\n",
    "    iou_scores = []\n",
    "    for true_labels, pred_labels in zip(y_true, y_pred):\n",
    "        true_set = set(true_labels)\n",
    "        pred_set = set(pred_labels)\n",
    "        intersection = len(true_set.intersection(pred_set))\n",
    "        union = len(true_set.union(pred_set))\n",
    "        if union == 0:\n",
    "            iou_scores.append(1.0)\n",
    "        else:\n",
    "            iou_scores.append(intersection / union)\n",
    "    return np.mean(iou_scores)\n",
    "\n",
    "# Step 4: Define the cross-validation process\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold = 1\n",
    "iou_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(f\"Training fold {fold}...\")\n",
    "    \n",
    "    # Split the data into training and test sets for this fold\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y_enc[train_index], Y_enc[test_index]\n",
    "    \n",
    "    # KNN classifier for multilabel classification\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    multi_knn = MultiOutputClassifier(knn, n_jobs=-1)\n",
    "    multi_knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predict using the KNN classifier\n",
    "    y_pred_enc = multi_knn.predict(X_test)\n",
    "\n",
    "    # Decode the predictions back to original multilabel format\n",
    "    y_pred = mlb.inverse_transform(y_pred_enc)\n",
    "    y_test_decoded = mlb.inverse_transform(y_test)\n",
    "\n",
    "    # Calculate IoU for this fold\n",
    "    fold_iou_score = calculate_iou(y_test_decoded, y_pred)\n",
    "    iou_scores.append(fold_iou_score)\n",
    "    \n",
    "    print(f\"Fold {fold} IoU score: {fold_iou_score:.4f}\")\n",
    "    fold += 1\n",
    "\n",
    "# Step 5: Calculate the average IoU across all folds\n",
    "average_iou = np.mean(iou_scores)\n",
    "print(f\"Average IoU score across all 5 folds: {average_iou:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ff8e47-ef9b-469c-aec7-e7bf0f846cee",
   "metadata": {},
   "source": [
    "Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ea697d7c-9087-43fc-9606-320a36ec67a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1...\n",
      "Fold 1 IoU score: 0.4577\n",
      "Training fold 2...\n",
      "Fold 2 IoU score: 0.4789\n",
      "Training fold 3...\n",
      "Fold 3 IoU score: 0.4540\n",
      "Training fold 4...\n",
      "Fold 4 IoU score: 0.4648\n",
      "Training fold 5...\n",
      "Fold 5 IoU score: 0.4323\n",
      "Average IoU score across all 5 folds: 0.4575\n"
     ]
    }
   ],
   "source": [
    "X = X1  # Concatenate audio, text, and video embeddings\n",
    "\n",
    "# Step 2: Convert Y to a binary matrix using MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y_enc = mlb.fit_transform(Y)  # Y is your category_id, encoded as multilabel\n",
    "\n",
    "# Step 3: Define IoU (Jaccard Similarity) for multilabel classification\n",
    "def calculate_iou(y_true, y_pred):\n",
    "    iou_scores = []\n",
    "    for true_labels, pred_labels in zip(y_true, y_pred):\n",
    "        true_set = set(true_labels)\n",
    "        pred_set = set(pred_labels)\n",
    "        intersection = len(true_set.intersection(pred_set))\n",
    "        union = len(true_set.union(pred_set))\n",
    "        if union == 0:\n",
    "            iou_scores.append(1.0)\n",
    "        else:\n",
    "            iou_scores.append(intersection / union)\n",
    "    return np.mean(iou_scores)\n",
    "\n",
    "# Step 4: Define the cross-validation process\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold = 1\n",
    "iou_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(f\"Training fold {fold}...\")\n",
    "    \n",
    "    # Split the data into training and test sets for this fold\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y_enc[train_index], Y_enc[test_index]\n",
    "    \n",
    "    # KNN classifier for multilabel classification\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    multi_knn = MultiOutputClassifier(knn, n_jobs=-1)\n",
    "    multi_knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predict using the KNN classifier\n",
    "    y_pred_enc = multi_knn.predict(X_test)\n",
    "\n",
    "    # Decode the predictions back to original multilabel format\n",
    "    y_pred = mlb.inverse_transform(y_pred_enc)\n",
    "    y_test_decoded = mlb.inverse_transform(y_test)\n",
    "\n",
    "    # Calculate IoU for this fold\n",
    "    fold_iou_score = calculate_iou(y_test_decoded, y_pred)\n",
    "    iou_scores.append(fold_iou_score)\n",
    "    \n",
    "    print(f\"Fold {fold} IoU score: {fold_iou_score:.4f}\")\n",
    "    fold += 1\n",
    "\n",
    "# Step 5: Calculate the average IoU across all folds\n",
    "average_iou = np.mean(iou_scores)\n",
    "print(f\"Average IoU score across all 5 folds: {average_iou:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383e6aaf-f381-474a-90de-902f39a67019",
   "metadata": {},
   "source": [
    "Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "97b01bc7-4191-46ce-b8dc-8f646ee04830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1...\n",
      "Fold 1 IoU score: 0.5809\n",
      "Training fold 2...\n",
      "Fold 2 IoU score: 0.5870\n",
      "Training fold 3...\n",
      "Fold 3 IoU score: 0.5653\n",
      "Training fold 4...\n",
      "Fold 4 IoU score: 0.5770\n",
      "Training fold 5...\n",
      "Fold 5 IoU score: 0.5151\n",
      "Average IoU score across all 5 folds: 0.5651\n"
     ]
    }
   ],
   "source": [
    "X = X2 # Concatenate audio, text, and video embeddings\n",
    "\n",
    "# Step 2: Convert Y to a binary matrix using MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y_enc = mlb.fit_transform(Y)  # Y is your category_id, encoded as multilabel\n",
    "\n",
    "# Step 3: Define IoU (Jaccard Similarity) for multilabel classification\n",
    "def calculate_iou(y_true, y_pred):\n",
    "    iou_scores = []\n",
    "    for true_labels, pred_labels in zip(y_true, y_pred):\n",
    "        true_set = set(true_labels)\n",
    "        pred_set = set(pred_labels)\n",
    "        intersection = len(true_set.intersection(pred_set))\n",
    "        union = len(true_set.union(pred_set))\n",
    "        if union == 0:\n",
    "            iou_scores.append(1.0)\n",
    "        else:\n",
    "            iou_scores.append(intersection / union)\n",
    "    return np.mean(iou_scores)\n",
    "\n",
    "# Step 4: Define the cross-validation process\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold = 1\n",
    "iou_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(f\"Training fold {fold}...\")\n",
    "    \n",
    "    # Split the data into training and test sets for this fold\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y_enc[train_index], Y_enc[test_index]\n",
    "    \n",
    "    # KNN classifier for multilabel classification\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    multi_knn = MultiOutputClassifier(knn, n_jobs=-1)\n",
    "    multi_knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predict using the KNN classifier\n",
    "    y_pred_enc = multi_knn.predict(X_test)\n",
    "\n",
    "    # Decode the predictions back to original multilabel format\n",
    "    y_pred = mlb.inverse_transform(y_pred_enc)\n",
    "    y_test_decoded = mlb.inverse_transform(y_test)\n",
    "\n",
    "    # Calculate IoU for this fold\n",
    "    fold_iou_score = calculate_iou(y_test_decoded, y_pred)\n",
    "    iou_scores.append(fold_iou_score)\n",
    "    \n",
    "    print(f\"Fold {fold} IoU score: {fold_iou_score:.4f}\")\n",
    "    fold += 1\n",
    "\n",
    "# Step 5: Calculate the average IoU across all folds\n",
    "average_iou = np.mean(iou_scores)\n",
    "print(f\"Average IoU score across all 5 folds: {average_iou:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4b30da-abc4-499d-8845-709559ec3181",
   "metadata": {},
   "source": [
    "Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e802f48a-b44a-4502-bee7-26cccf048c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training fold 1...\n",
      "Fold 1 IoU score: 0.6485\n",
      "Training fold 2...\n",
      "Fold 2 IoU score: 0.6692\n",
      "Training fold 3...\n",
      "Fold 3 IoU score: 0.6248\n",
      "Training fold 4...\n",
      "Fold 4 IoU score: 0.5852\n",
      "Training fold 5...\n",
      "Fold 5 IoU score: 0.5880\n",
      "Average IoU score across all 5 folds: 0.6231\n"
     ]
    }
   ],
   "source": [
    "X = X3 # Concatenate audio, text, and video embeddings\n",
    "\n",
    "# Step 2: Convert Y to a binary matrix using MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "Y_enc = mlb.fit_transform(Y)  # Y is your category_id, encoded as multilabel\n",
    "\n",
    "# Step 3: Define IoU (Jaccard Similarity) for multilabel classification\n",
    "def calculate_iou(y_true, y_pred):\n",
    "    iou_scores = []\n",
    "    for true_labels, pred_labels in zip(y_true, y_pred):\n",
    "        true_set = set(true_labels)\n",
    "        pred_set = set(pred_labels)\n",
    "        intersection = len(true_set.intersection(pred_set))\n",
    "        union = len(true_set.union(pred_set))\n",
    "        if union == 0:\n",
    "            iou_scores.append(1.0)\n",
    "        else:\n",
    "            iou_scores.append(intersection / union)\n",
    "    return np.mean(iou_scores)\n",
    "\n",
    "# Step 4: Define the cross-validation process\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "fold = 1\n",
    "iou_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(f\"Training fold {fold}...\")\n",
    "    \n",
    "    # Split the data into training and test sets for this fold\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = Y_enc[train_index], Y_enc[test_index]\n",
    "    \n",
    "    # KNN classifier for multilabel classification\n",
    "    knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    multi_knn = MultiOutputClassifier(knn, n_jobs=-1)\n",
    "    multi_knn.fit(X_train, y_train)\n",
    "\n",
    "    # Predict using the KNN classifier\n",
    "    y_pred_enc = multi_knn.predict(X_test)\n",
    "\n",
    "    # Decode the predictions back to original multilabel format\n",
    "    y_pred = mlb.inverse_transform(y_pred_enc)\n",
    "    y_test_decoded = mlb.inverse_transform(y_test)\n",
    "\n",
    "    # Calculate IoU for this fold\n",
    "    fold_iou_score = calculate_iou(y_test_decoded, y_pred)\n",
    "    iou_scores.append(fold_iou_score)\n",
    "    \n",
    "    print(f\"Fold {fold} IoU score: {fold_iou_score:.4f}\")\n",
    "    fold += 1\n",
    "\n",
    "# Step 5: Calculate the average IoU across all folds\n",
    "average_iou = np.mean(iou_scores)\n",
    "print(f\"Average IoU score across all 5 folds: {average_iou:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab36461-6a41-4f05-88c7-0df70b8c57e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (video-tag)",
   "language": "python",
   "name": "video-tag"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
