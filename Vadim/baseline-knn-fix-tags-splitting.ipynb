{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline для хакатона Rutube по задаче \"Теггирование видео\"\n",
    "\n",
    "В рамках данного ноутбука мы рассмотрим наивный подход к решению поставленной задачи: векторный поиск навания видео в базе векторов тегов.\n",
    "\n",
    "В конце есть пример получения sample_submission.csv - пример файла, который нужно загрузить на лидерборд.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IAB_tags.csv\t\t      download_trimmed_dataset.ipynb\n",
      "baseline-newembeddings.ipynb  requirements.txt\n",
      "baseline.ipynb\t\t      train_data_categories.csv\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import json\n",
    "from tqdm.autonotebook import tqdm\n",
    "import numpy as np \n",
    "import faiss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Берем данные с id видео и его названием, также загружаем иерархические теги"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['video_id', 'title'], dtype='object')\n",
      "                           video_id  \\\n",
      "0  9007f33c8347924ffa12f922da2a179d   \n",
      "1  9012707c45233bd601dead57bc9e2eca   \n",
      "2  e01d6ebabbc27e323fa1b7c581e9b96a   \n",
      "3  a00b145242be3ebc3b311455e94917af   \n",
      "4  b01a682bf4dfcc09f1e8fac5bc18785a   \n",
      "\n",
      "                                               title  \n",
      "0  Пацанский клининг. Шоу «ЧистоТачка» | Повелите...  \n",
      "1  СarJitsu. 3 сезон, 6 серия. Нарек Симонян vs Ж...  \n",
      "2  Злые языки | Выпуск 1, Сезон 1 | Непорочность ...  \n",
      "3                 $1000 шоу | 1 выпуск | Автобоулинг  \n",
      "4                    В РОТ МНЕ НОТЫ #1 ВИТА ЧИКОВАНИ  \n",
      "  Уровень 1 (iab)         Уровень 2 (iab)      Уровень 3 (iab)\n",
      "0       Транспорт                     NaN                  NaN\n",
      "1       Транспорт  Типы кузова автомобиля                  NaN\n",
      "2       Транспорт  Типы кузова автомобиля  Грузовой автомобиль\n",
      "3       Транспорт  Типы кузова автомобиля                Седан\n",
      "4       Транспорт  Типы кузова автомобиля            Универсал\n",
      "Index(['Уровень 1 (iab)', 'Уровень 2 (iab)', 'Уровень 3 (iab)'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"baseline/train_data_categories.csv\",).dropna()[['video_id', 'title']]\n",
    "taxonomy = pd.read_csv(\"baseline/IAB_tags.csv\")\n",
    "\n",
    "print(data.columns)\n",
    "print(data.head(5))\n",
    "\n",
    "print(taxonomy.head(5))\n",
    "\n",
    "print(taxonomy.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Для создания эмбеддинга берем русскоязычный Берт и загружаем в sentence transformer, который позволяет создавать эмбеддинг для всего предложения и сам обрезает его до максимально возможного числа токенов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name DeepPavlov/rubert-base-cased-sentence. Creating a new one with mean pooling.\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('DeepPavlov/rubert-base-cased-sentence', )\n",
    "dim = 768 # размер вектора эмбеддинга"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Создаем эмбеддинги для названий видео"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['title_vector'] = data['title'].apply(lambda l: model.encode(l, convert_to_tensor=True).cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Создаем векторы для тегов:\n",
    " Для каждого 1 уровня иерархии в отдельности и для следующих уровней формата уровень 1: уровень 2: уровень 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags():\n",
    "    tags = {}\n",
    "    for i, row in tqdm(taxonomy.iterrows()):\n",
    "        if isinstance(row['Уровень 1 (iab)'], str):\n",
    "            tags[row['Уровень 1 (iab)']] = model.encode(row['Уровень 1 (iab)'], convert_to_tensor=True).cpu().numpy()#.tolist()\n",
    "        if isinstance(row['Уровень 2 (iab)'], str):\n",
    "            tags[row['Уровень 1 (iab)']+ \": \"+row['Уровень 2 (iab)']] = model.encode(row['Уровень 1 (iab)']+ \": \"+row['Уровень 2 (iab)'], convert_to_tensor=True).cpu().numpy()#.tolist()\n",
    "        if isinstance(row['Уровень 3 (iab)'], str):\n",
    "            tags[row['Уровень 1 (iab)']+ \": \"+row['Уровень 2 (iab)']+\": \"+row['Уровень 3 (iab)']] = model.encode(row['Уровень 1 (iab)']+ \": \"+row['Уровень 2 (iab)']+\": \"+row['Уровень 3 (iab)'], convert_to_tensor=True).cpu().numpy()#.tolist()\n",
    "    return tags\n",
    "\n",
    "# tags = get_tags()\n",
    "# tags_list = list(tags.keys())\n",
    "# vectors = np.array(list(tags.values()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Создаем векторную базу faiss для эффективного векторного поиска"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "610\n"
     ]
    }
   ],
   "source": [
    "index = faiss.index_factory(dim, \"Flat\", faiss.METRIC_INNER_PRODUCT)\n",
    "print(index.ntotal)\n",
    "index.add(vectors)\n",
    "print(index.ntotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Смотрим несколько получившихся примеров \n",
    "Генерим по 3 близких предсказания для каждого названия видео"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORES [280.2826  268.9419  264.77997]\n",
      "PREDICTION_by_title ['Семья и отношения: Развод' 'Массовая культура: Смерти знаменитостей'\n",
      " 'Массовая культура: Скандалы знаменитостей']\n",
      "SAMPLE Пацанский клининг. Шоу «ЧистоТачка» | Повелитель ночи | Выпуск 17\n",
      "\n",
      "\n",
      "SCORES [248.28537 242.65976 241.96161]\n",
      "PREDICTION_by_title ['Массовая культура: Скандалы знаменитостей' 'Игры: Киберспорт'\n",
      " 'Спорт: Дартс']\n",
      "SAMPLE СarJitsu. 3 сезон, 6 серия. Нарек Симонян vs Жека Секси\n",
      "\n",
      "\n",
      "SCORES [291.92664 287.7805  280.69467]\n",
      "PREDICTION_by_title ['Семья и отношения: Развод'\n",
      " 'Медицина: Медицинские направления: Простуда и грипп'\n",
      " 'Новости и политика: Политика: Война и конфликты']\n",
      "SAMPLE Злые языки | Выпуск 1, Сезон 1 | Непорочность Даны Борисовой\n",
      "\n",
      "\n",
      "SCORES [247.24628 243.45216 236.21658]\n",
      "PREDICTION_by_title ['Музыка и аудио: Мировые хиты'\n",
      " 'События и достопримечательности: Личные события: День рождения'\n",
      " 'Массовая культура: Скандалы знаменитостей']\n",
      "SAMPLE $1000 шоу | 1 выпуск | Автобоулинг\n",
      "\n",
      "\n",
      "SCORES [276.93286 271.74152 269.93735]\n",
      "PREDICTION_by_title ['Спорт: Спортивное оборудование' 'Личные финансы: Страхование'\n",
      " 'Медицина: Фармацевтические препараты']\n",
      "SAMPLE В РОТ МНЕ НОТЫ #1 ВИТА ЧИКОВАНИ\n",
      "\n",
      "\n",
      "SCORES [304.03162 250.46735 240.5711 ]\n",
      "PREDICTION_by_title ['Стиль и красота: Высокая мода' 'Животные: Крупные животные'\n",
      " 'Образование: Высшее образование']\n",
      "SAMPLE Смешная история | Выпуск 3\n",
      "\n",
      "\n",
      "SCORES [286.30878 282.53616 280.7779 ]\n",
      "PREDICTION_by_title ['Медицина: Медицинские направления: Сексология'\n",
      " 'Образование: Высшее образование: Аспирантура и магистратура'\n",
      " 'Медицина: Медицинские направления: Психиатрия']\n",
      "SAMPLE Женсовет I Выпуск 6 I Мужчина в новой феминистической реальности I В гостях психолог Алёна Романова.\n",
      "\n",
      "\n",
      "SCORES [298.30527 296.332   294.7121 ]\n",
      "PREDICTION_by_title ['Личные финансы: Страхование: Страхование жизни'\n",
      " 'Личные финансы: Страхование'\n",
      " 'Личные финансы: Страхование: Страхование путешествий']\n",
      "SAMPLE Осторожно, мошенники! Онлайн экстрасенс\n",
      "\n",
      "\n",
      "SCORES [249.85034 248.16301 245.61841]\n",
      "PREDICTION_by_title ['События и достопримечательности: События мира моды'\n",
      " 'Спорт: Олимпийские виды спорта: Зимние олимпийские виды спорта'\n",
      " 'Фильмы и анимация: Мировой кинематограф']\n",
      "SAMPLE Kuzov Studio в ГрандТуре «Байкальская миля 2021». Омск\n",
      "\n",
      "\n",
      "SCORES [241.99704 238.9707  232.90738]\n",
      "PREDICTION_by_title ['Карьера: Профессиональная подготовка' 'Образование: Домашние задания'\n",
      " 'Образование: Домашнее обучение']\n",
      "SAMPLE Салют, Начальник | 7 серия\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "topn = 3\n",
    "scores, predictions = index.search(np.array(data['title_vector'].to_list()[:10]), topn)\n",
    "for j, i in enumerate(predictions):\n",
    "    print(\"SCORES\", scores[j])\n",
    "    print(\"PREDICTION_by_title\", np.array(tags_list)[predictions[j]])\n",
    "    print(\"SAMPLE\", data['title'].to_list()[:10][j])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Для формирования sample_submission будем брать только наилучшее предсказания для каждого видео\n",
    "Сейчас у вас уже есть sample_submission с нужными для скоринга video_id, но пока нет информации о видео, она появится ближе к концу хакатона\n",
    "Для примера прогоним через весь train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "topn=1\n",
    "sample_submission = pd.DataFrame(data=data['video_id'].to_list(), columns=['video_id'])\n",
    "sample_submission['predicted_tags']=np.nan\n",
    "sample_submission['predicted_tags'] = sample_submission['predicted_tags'].astype('object')\n",
    "\n",
    "for i, row in data.iterrows():\n",
    "    scores, predictions = index.search(np.array([row['title_vector']]), topn)\n",
    "    index_i = sample_submission[sample_submission.video_id == row.video_id].index\n",
    "    sample_submission.at[index_i[0], 'predicted_tags'] = [tags_list[predictions[0][0]]] # вытаскиваем предсказание из "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           video_id  \\\n",
      "0  9007f33c8347924ffa12f922da2a179d   \n",
      "1  9012707c45233bd601dead57bc9e2eca   \n",
      "2  e01d6ebabbc27e323fa1b7c581e9b96a   \n",
      "3  a00b145242be3ebc3b311455e94917af   \n",
      "4  b01a682bf4dfcc09f1e8fac5bc18785a   \n",
      "\n",
      "                                          tags  \n",
      "0                  [Семья и отношения: Развод]  \n",
      "1  [Массовая культура: Скандалы знаменитостей]  \n",
      "2                  [Семья и отношения: Развод]  \n",
      "3               [Музыка и аудио: Мировые хиты]  \n",
      "4             [Спорт: Спортивное оборудование]  \n"
     ]
    }
   ],
   "source": [
    "print(sample_submission.head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### В predicted_tags нужно записывать list тегов, например ['Карьера: Cтажировки', 'Карьера: Составление резюме'] или ['Массовая культура: Сериалы']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"sample_submission.csv\", index_label=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IAB_tags.csv\t\t\trequirements.txt\n",
      "baseline-newembeddings.ipynb\ttrain_data_categories.csv\n",
      "baseline.ipynb\t\t\tскрипт_проверки_Rutube.ipynb\n",
      "download_trimmed_dataset.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tags(tag_list):\n",
    "    final_tag_list = []\n",
    "    for tag in tag_list:\n",
    "        tags = tag.split(\": \")\n",
    "        if len(tags) == 3:\n",
    "            final_tag_list.append(tags[0])\n",
    "            final_tag_list.append(tags[0] + \": \" + tags[1])\n",
    "            final_tag_list.append(tags[0]+ \": \" + tags[1] + \": \" + tags[2])\n",
    "        elif len(tags) == 2:\n",
    "            final_tag_list.append(tags[0])\n",
    "            final_tag_list.append(tags[0] + \": \" + tags[1])\n",
    "        elif len(tags) == 1:\n",
    "            final_tag_list.append(tags[0])\n",
    "        else:\n",
    "            print(\"NOT IMPLEMENTED!!!!\", tag)\n",
    "    return final_tag_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Ошибка при загрузке решения участника",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[122], line 52\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m     pred_submission \u001b[38;5;241m=\u001b[39m \u001b[43msample_submission\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sample_submission' is not defined",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[122], line 54\u001b[0m\n\u001b[1;32m     52\u001b[0m     pred_submission \u001b[38;5;241m=\u001b[39m sample_submission\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mОшибка при загрузке решения участника\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     56\u001b[0m     true_submission \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbaseline/train_data_categories.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mdropna()\n",
      "\u001b[0;31mAssertionError\u001b[0m: Ошибка при загрузке решения участника"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import argparse\n",
    "import ast\n",
    "import numpy as np\n",
    "\n",
    "def iou_metric(ground_truth, predictions):\n",
    "    iou =  len(set.intersection(set(ground_truth), set(predictions)))\n",
    "    iou = iou/(len(set(ground_truth).union(set(predictions))))\n",
    "    print(iou, ground_truth, predictions)\n",
    "    return iou\n",
    "\n",
    "def split_tags(tag_list):\n",
    "    final_tag_list = []\n",
    "    for tag in tag_list:\n",
    "        tags = [tag.strip().lower() for tag in tag.split(\":\")]\n",
    "        if len(tags) == 3:\n",
    "            final_tag_list.append(tags[0])\n",
    "            final_tag_list.append(tags[0] + \": \" + tags[1])\n",
    "            final_tag_list.append(tags[0]+ \": \" + tags[1] + \": \" + tags[2])\n",
    "        elif len(tags) == 2:\n",
    "            final_tag_list.append(tags[0])\n",
    "            final_tag_list.append(tags[0] + \": \" + tags[1])\n",
    "        elif len(tags) == 1:\n",
    "            final_tag_list.append(tags[0])\n",
    "        else:\n",
    "            print(\"NOT IMPLEMENTED!!!!\", tag)\n",
    "    return final_tag_list\n",
    "\n",
    "\n",
    "def find_iou_for_sample_submission(pred_submission, true_submission):\n",
    "    ground_truth_df = true_submission\n",
    "    ground_truth_df[\"tags\"] = ground_truth_df[\"tags\"].apply(lambda l: l.split(', '))\n",
    "    ground_truth_df[\"tags_split\"] = ground_truth_df[\"tags\"].apply(lambda l: split_tags(l))\n",
    "\n",
    "    predictions_df = pred_submission\n",
    "    # predictions_df[\"predicted_tags\"] = predictions_df[\"predicted_tags\"].apply(ast.literal_eval)\n",
    "    predictions_df[\"predicted_tags_split\"] = predictions_df[\"predicted_tags\"].apply(lambda l: split_tags(l))\n",
    "    iou=0\n",
    "    counter = 0\n",
    "    for i, row in ground_truth_df.iterrows():\n",
    "        predicted_tags = predictions_df[predictions_df[\"video_id\"]==row[\"video_id\"]][\"predicted_tags_split\"].values[0]\n",
    "        iou_temp=iou_metric(row['tags_split'], predicted_tags)\n",
    "        iou+=iou_temp\n",
    "        counter+=1\n",
    "\n",
    "    return iou/counter\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "\n",
    "try:\n",
    "    pred_submission = sample_submission\n",
    "except Exception:\n",
    "    assert False, 'Ошибка при загрузке решения участника'\n",
    "try:\n",
    "    true_submission = pd.read_csv(\"baseline/train_data_categories.csv\").dropna()\n",
    "except Exception:\n",
    "    assert False, 'Ошибка при загрузке эталонного решения'\n",
    "\n",
    "\n",
    "final_score = find_iou_for_sample_submission(pred_submission, true_submission)\n",
    "print(\"FINAL_SCORE\", final_score ) #final_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  knn on embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.preprocessing import StandardScaler, LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Уровень 1 (iab)</th>\n",
       "      <th>Уровень 2 (iab)</th>\n",
       "      <th>Уровень 3 (iab)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Транспорт</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Транспорт</td>\n",
       "      <td>Типы кузова автомобиля</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Транспорт</td>\n",
       "      <td>Типы кузова автомобиля</td>\n",
       "      <td>Грузовой автомобиль</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Транспорт</td>\n",
       "      <td>Типы кузова автомобиля</td>\n",
       "      <td>Седан</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Транспорт</td>\n",
       "      <td>Типы кузова автомобиля</td>\n",
       "      <td>Универсал</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Уровень 1 (iab)         Уровень 2 (iab)      Уровень 3 (iab)\n",
       "0       Транспорт                     NaN                  NaN\n",
       "1       Транспорт  Типы кузова автомобиля                  NaN\n",
       "2       Транспорт  Типы кузова автомобиля  Грузовой автомобиль\n",
       "3       Транспорт  Типы кузова автомобиля                Седан\n",
       "4       Транспорт  Типы кузова автомобиля            Универсал"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = pd.read_csv(\"baseline/IAB_tags.csv\")\n",
    "categories.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f411e74f51649329d5e6ad7c54e169d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_tags_to_labels():\n",
    "    tags = {}\n",
    "    for i, row in tqdm(taxonomy.iterrows()):\n",
    "        if isinstance(row['Уровень 3 (iab)'], str):\n",
    "            tags[row['Уровень 1 (iab)'].strip().lower()+ \": \"+row['Уровень 2 (iab)'].strip().lower()+\": \"+row['Уровень 3 (iab)'].strip().lower()] = i\n",
    "        elif isinstance(row['Уровень 2 (iab)'], str):\n",
    "            tags[row['Уровень 1 (iab)'].strip().lower()+ \": \"+row['Уровень 2 (iab)'].strip().lower()] = i\n",
    "        elif isinstance(row['Уровень 1 (iab)'], str):\n",
    "            tags[row['Уровень 1 (iab)'].strip().lower()] = i\n",
    "        # if isinstance(row['Уровень 1 (iab)'], str):\n",
    "        #     # tags[i] = row['Уровень 1 (iab)']\n",
    "        #     tags.append(row['Уровень 1 (iab)'].strip())\n",
    "        # if isinstance(row['Уровень 2 (iab)'], str):\n",
    "        #     # tags[i] = row['Уровень 1 (iab)']+ \": \"+row['Уровень 2 (iab)']\n",
    "        #     tags.append(row['Уровень 1 (iab)'].strip()+ \": \"+row['Уровень 2 (iab)'].strip())\n",
    "        # if isinstance(row['Уровень 3 (iab)'], str):\n",
    "        #     # tags[row['Уровень 1 (iab)']+ \": \"+row['Уровень 2 (iab)']+\": \"+row['Уровень 3 (iab)']] = i\n",
    "        #     tags.append(row['Уровень 1 (iab)'].strip()+ \": \"+row['Уровень 2 (iab)'].strip()+\": \"+row['Уровень 3 (iab)'].strip())\n",
    "    return tags\n",
    "\n",
    "# labels_to_tags = create_labels_tags()\n",
    "tags_to_labels = create_tags_to_labels()\n",
    "tags_to_labels[\"фильмы и анимация: фильмы и анимация\"] = tags_to_labels[\"фильмы и анимация\"]\n",
    "labels_to_tags = {str(v): k for k, v in tags_to_labels.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingStorage:\n",
    "    def __init__(self, labels=None, filenames=None, embeddings=None):\n",
    "        \"\"\"\n",
    "        Initialize the EmbeddingStorage class.\n",
    "        \n",
    "        Args:\n",
    "            labels (list or np.ndarray): An array of labels for the embeddings.\n",
    "            filenames (list or np.ndarray): An array of filenames associated with the embeddings.\n",
    "            embeddings (np.ndarray): A NumPy array containing all embeddings.\n",
    "        \"\"\"\n",
    "        self.labels = np.array(labels) if labels is not None else np.array([])\n",
    "        self.filenames = np.array(filenames) if filenames is not None else np.array([])\n",
    "        self.embeddings = np.array(embeddings) if embeddings is not None else np.empty((0,))\n",
    "\n",
    "    def add_embedding(self, label, filename, embedding):\n",
    "        \"\"\"\n",
    "        Add a new embedding, along with its label and filename.\n",
    "        \n",
    "        Args:\n",
    "            label (int or str): The label of the embedding.\n",
    "            filename (str): The filename associated with the embedding.\n",
    "            embedding (np.ndarray or torch.Tensor): The embedding to add (can be a NumPy array or Tensor).\n",
    "        \"\"\"\n",
    "        if isinstance(embedding, np.ndarray):\n",
    "            emb_array = embedding\n",
    "        else:\n",
    "            # Convert torch.Tensor to NumPy\n",
    "            emb_array = embedding.cpu().numpy()\n",
    "        \n",
    "        # Append the new data\n",
    "        self.labels = np.append(self.labels, label)\n",
    "        self.filenames = np.append(self.filenames, filename)\n",
    "        \n",
    "        if self.embeddings.size == 0:\n",
    "            self.embeddings = emb_array.reshape(1, -1)\n",
    "        else:\n",
    "            self.embeddings = np.vstack([self.embeddings, emb_array])\n",
    "\n",
    "    def save_to_file(self, file_path):\n",
    "        \"\"\"\n",
    "        Save the embeddings, labels, and filenames to a file (as .npz).\n",
    "        \n",
    "        Args:\n",
    "            file_path (str): The path to save the .npz file.\n",
    "        \"\"\"\n",
    "        np.savez(file_path, labels=self.labels, filenames=self.filenames, embeddings=self.embeddings)\n",
    "\n",
    "    @classmethod\n",
    "    def load_from_file(cls, file_path):\n",
    "        \"\"\"\n",
    "        Load embeddings, labels, and filenames from a saved .npz file.\n",
    "        \n",
    "        Args:\n",
    "            file_path (str): The path to the .npz file to load.\n",
    "        \n",
    "        Returns:\n",
    "            EmbeddingStorage: An instance of EmbeddingStorage with loaded data.\n",
    "        \"\"\"\n",
    "        data = np.load(file_path)\n",
    "        return cls(labels=data['labels'], filenames=data['filenames'], embeddings=data['embeddings'])\n",
    "\n",
    "    def get_embedding_by_filename(self, filename):\n",
    "        \"\"\"\n",
    "        Retrieve an embedding by its associated filename.\n",
    "        \n",
    "        Args:\n",
    "            filename (str): The filename to search for.\n",
    "        \n",
    "        Returns:\n",
    "            np.ndarray: The corresponding embedding or None if not found.\n",
    "        \"\"\"\n",
    "        if filename in self.filenames:\n",
    "            idx = np.where(self.filenames == filename)[0][0]\n",
    "            return self.embeddings[idx]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def join_on_videoname(self, other_storage):\n",
    "        \"\"\"\n",
    "        Join two EmbeddingStorage objects on the 'videoname' (filename). The embeddings will be stored as tuples.\n",
    "        \n",
    "        Args:\n",
    "            other_storage (EmbeddingStorage): Another EmbeddingStorage object to join with.\n",
    "        \n",
    "        Returns:\n",
    "            EmbeddingStorage: A new EmbeddingStorage object with merged data (embedding tuples).\n",
    "        \"\"\"\n",
    "        # Find common filenames\n",
    "        common_filenames = np.intersect1d(self.filenames, other_storage.filenames)\n",
    "        \n",
    "        # Initialize lists to store merged data\n",
    "        merged_labels = []\n",
    "        merged_filenames = []\n",
    "        merged_embeddings = []\n",
    "        \n",
    "        for filename in common_filenames:\n",
    "            # Get embeddings for the common filename from both storages\n",
    "            idx_self = np.where(self.filenames == filename)[0][0]\n",
    "            idx_other = np.where(other_storage.filenames == filename)[0][0]\n",
    "            \n",
    "            emb_self = self.embeddings[idx_self]\n",
    "            emb_other = other_storage.embeddings[idx_other]\n",
    "            \n",
    "            # Store embeddings as a tuple\n",
    "            merged_embedding = (emb_self, emb_other)\n",
    "            \n",
    "            # Get the label from the first storage (could be changed based on use case)\n",
    "            merged_label = self.labels[idx_self]\n",
    "            \n",
    "            # Append to the merged data\n",
    "            merged_labels.append(merged_label)\n",
    "            merged_filenames.append(filename)\n",
    "            merged_embeddings.append(merged_embedding)\n",
    "        \n",
    "        # Convert lists to numpy arrays\n",
    "        merged_labels = np.array(merged_labels)\n",
    "        merged_filenames = np.array(merged_filenames)\n",
    "        merged_embeddings = np.array(merged_embeddings, dtype=object)\n",
    "        \n",
    "        # Return a new EmbeddingStorage instance with merged data\n",
    "        return EmbeddingStorage(labels=merged_labels, filenames=merged_filenames, embeddings=merged_embeddings)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Return the number of embeddings stored.\n",
    "        \"\"\"\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Retrieve the label, filename, and embedding by index.\n",
    "        \n",
    "        Args:\n",
    "            idx (int): The index of the embedding to retrieve.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: A tuple containing (label, filename, embedding).\n",
    "        \"\"\"\n",
    "        if idx >= len(self.labels):\n",
    "            raise IndexError(\"Index out of range\")\n",
    "        return self.labels[idx], self.filenames[idx], self.embeddings[idx]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"EmbeddingStorage(labels={len(self.labels)}, filenames={len(self.filenames)}, embeddings_shape={self.embeddings.shape})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vivit = EmbeddingStorage.load_from_file(\"vivit.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 0 is out of bounds for axis 0 with size 0\n",
      "b4d70f82038d1d97f1b3ce2a493d12c8.mp4\n",
      "wrong dataset row\n"
     ]
    }
   ],
   "source": [
    "Y_prepare = []\n",
    "max_len = 10\n",
    "for filename in vivit.filenames:\n",
    "    _y = [-1 for _ in range(10)]\n",
    "    try:\n",
    "        index = 0\n",
    "        for tag in split_tags(filter(lambda x: x != \"\", train_data[\"tags\"][train_data[\"video_id\"] == filename[:-4]].values[0].split(\",\"))):\n",
    "            if label := tags_to_labels.get(tag.strip().lower()):\n",
    "                _y[index] = label\n",
    "                index += 1\n",
    "        # for i, v in enumerate(_y):\n",
    "        #     _y[i] = v\n",
    "        \n",
    "    except IndexError as e:\n",
    "        print(e)\n",
    "        print(filename)\n",
    "        print(\"wrong dataset row\")\n",
    "    Y_prepare.append(_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[121, 135, 429, ...,  -1,  -1,  -1],\n",
       "       [398, 137, 150, ...,  -1,  -1,  -1],\n",
       "       [398, 406,  -1, ...,  -1,  -1,  -1],\n",
       "       ...,\n",
       "       [566, 577, 579, ...,  -1,  -1,  -1],\n",
       "       [398,  -1,  -1, ...,  -1,  -1,  -1],\n",
       "       [398, 346,  -1, ...,  -1,  -1,  -1]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Singleton array array(1049) cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[167], line 24\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Y: np.array = np.array([\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m#     [tags_to_labels[tag] for tag in split_tags(train_data[\"tags\"][train_data[\"video_id\"] == y[:-4]].values[0])] \u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#     for y in vivit.filenames])\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Y = np.array(Y_prepare)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m Y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(Y_prepare)\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m train_indices, test_indices \u001b[38;5;129;01min\u001b[39;00m kf\u001b[38;5;241m.\u001b[39msplit(np\u001b[38;5;241m.\u001b[39marange(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]), Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# X_train, X_test = X[train_indices], X[test_indices]\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# print(X_train.shape, X_test.shape)\u001b[39;00m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# print(train_indices, test_indices)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m \n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# print(f\"IoU: {iou_total}\")\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:406\u001b[0m, in \u001b[0;36m_BaseKFold.split\u001b[0;34m(self, X, y, groups)\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msplit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, groups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    383\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Generate indices to split data into training and test set.\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \n\u001b[1;32m    385\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;124;03m        The testing set indices for that split.\u001b[39;00m\n\u001b[1;32m    405\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 406\u001b[0m     X, y, groups \u001b[38;5;241m=\u001b[39m \u001b[43mindexable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    407\u001b[0m     n_samples \u001b[38;5;241m=\u001b[39m _num_samples(X)\n\u001b[1;32m    408\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_splits \u001b[38;5;241m>\u001b[39m n_samples:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:514\u001b[0m, in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Make arrays indexable for cross-validation.\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \n\u001b[1;32m    486\u001b[0m \u001b[38;5;124;03mChecks consistent length, passes through None, and ensures that everything\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;124;03m[[1, 2, 3], array([2, 3, 4]), None, <...Sparse...dtype 'int64'...shape (3, 1)>]\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    513\u001b[0m result \u001b[38;5;241m=\u001b[39m [_make_indexable(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m iterables]\n\u001b[0;32m--> 514\u001b[0m \u001b[43mcheck_consistent_length\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:454\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_consistent_length\u001b[39m(\u001b[38;5;241m*\u001b[39marrays):\n\u001b[1;32m    437\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that all arrays have consistent first dimensions.\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \n\u001b[1;32m    439\u001b[0m \u001b[38;5;124;03m    Checks whether all objects in arrays have the same shape or length.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;124;03m    >>> check_consistent_length(a, b)\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 454\u001b[0m     lengths \u001b[38;5;241m=\u001b[39m [_num_samples(X) \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m arrays \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    455\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:454\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcheck_consistent_length\u001b[39m(\u001b[38;5;241m*\u001b[39marrays):\n\u001b[1;32m    437\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that all arrays have consistent first dimensions.\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \n\u001b[1;32m    439\u001b[0m \u001b[38;5;124;03m    Checks whether all objects in arrays have the same shape or length.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;124;03m    >>> check_consistent_length(a, b)\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 454\u001b[0m     lengths \u001b[38;5;241m=\u001b[39m [\u001b[43m_num_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m X \u001b[38;5;129;01min\u001b[39;00m arrays \u001b[38;5;28;01mif\u001b[39;00m X \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    455\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py:382\u001b[0m, in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m x\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 382\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    383\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSingleton array \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m cannot be considered a valid collection.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m x\n\u001b[1;32m    384\u001b[0m         )\n\u001b[1;32m    385\u001b[0m     \u001b[38;5;66;03m# Check that shape is returning an integer or default to len\u001b[39;00m\n\u001b[1;32m    386\u001b[0m     \u001b[38;5;66;03m# Dask dataframes may not return numeric shape[0] value\u001b[39;00m\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], numbers\u001b[38;5;241m.\u001b[39mIntegral):\n",
      "\u001b[0;31mTypeError\u001b[0m: Singleton array array(1049) cannot be considered a valid collection."
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "seed = 42\n",
    "n_splits = 2\n",
    "iou_total = 0\n",
    "\n",
    "\n",
    "def calc_iou(y_true, y_pred):\n",
    "    iou = 0\n",
    "    print(y_true, y_pred)\n",
    "    for ground_truth, prediction in zip(y_true, y_pred):\n",
    "        iou += iou_metric(ground_truth, prediction)\n",
    "    return iou / len(y_true)\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=seed)\n",
    "X: np.array = vivit.embeddings\n",
    "# Y: np.array = np.array([\n",
    "#     [tags_to_labels[tag] for tag in split_tags(train_data[\"tags\"][train_data[\"video_id\"] == y[:-4]].values[0])] \n",
    "#     for y in vivit.filenames])\n",
    "# Y = np.array(Y_prepare)\n",
    "Y = np.array(Y_prepare)\n",
    "for train_indices, test_indices in kf.split(np.arange(X.shape[0]), Y.shape[0], ):\n",
    "    ...\n",
    "    # X_train, X_test = X[train_indices], X[test_indices]\n",
    "    # print(X_train.shape, X_test.shape)\n",
    "    # print(train_indices, test_indices)\n",
    "    # Y_train_labels, Y_test_labels = Y[train_indices], Y[test_indices]\n",
    "    # # Y_train_labels = [tags_to_labels[y] for y in Y_train]\n",
    "    # # Y_test_labels = [tags_to_labels[y] for y in Y_test]\n",
    "    # model = KNeighborsClassifier(n_neighbors=3)\n",
    "    # model.fit(X_train, Y_train_labels)\n",
    "    # # Y_pred = np.argsort(model.predict_proba(X_test), axis=1)[:, :5]\n",
    "    # probas = model.predict_proba(X_test)\n",
    "    # Y_pred_labels = np.argsort(model.predict_proba(X_test), axis=1)[:, :5]\n",
    "    # Y_pred = [split_tags([labels_to_tags[y]])for y in Y_pred_labels]\n",
    "    # Y_test_labels_splitted = [split_tags([labels_to_tags[y]]) for y in Y_test_labels]\n",
    "    # # print(classification_report(Y_test, Y_pred))\n",
    "    # iou = calc_iou(Y_pred, Y_test_labels_splitted)\n",
    "    # iou_total += iou\n",
    "    # print(f\"test len: {len(Y_test_labels_splitted)}, len train: {len(Y_train_labels)}\")\n",
    "\n",
    "# iou_total /= n_splits\n",
    "\n",
    "# print(f\"IoU: {iou_total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "  Train set shape: X (839, 768), Y (839, 10)\n",
      "  Test set shape:  X (210, 768), Y (210, 10)\n",
      "[array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]]), array([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       ...,\n",
      "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.33333333, 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ]]), array([[0.66666667, 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       ...,\n",
      "       [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [0.66666667, 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ]]), array([[1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       ...,\n",
      "       [0.33333333, 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       [1.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.        ]]), array([[1., 0., 0., ..., 0., 0., 0.],\n",
      "       [1., 0., 0., ..., 0., 0., 0.],\n",
      "       [1., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [1., 0., 0., ..., 0., 0., 0.],\n",
      "       [1., 0., 0., ..., 0., 0., 0.],\n",
      "       [1., 0., 0., ..., 0., 0., 0.]]), array([[1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [0.66666667, 0.        , 0.        , 0.33333333],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [0.66666667, 0.33333333, 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [0.66666667, 0.33333333, 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [0.66666667, 0.        , 0.33333333, 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ],\n",
      "       [1.        , 0.        , 0.        , 0.        ]]), array([[1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [0.66666667, 0.33333333],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ],\n",
      "       [1.        , 0.        ]]), array([[1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.]]), array([[1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.]]), array([[1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (10, 210) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[175], line 42\u001b[0m\n\u001b[1;32m     40\u001b[0m     probas \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict_proba(X_test)\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28mprint\u001b[39m(probas)\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margsort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m[:, :\u001b[38;5;241m5\u001b[39m])\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# Y_pred_labels = np.argsort(model.predict_proba(X_test), axis=1)[:, :5]\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# Y_pred = [split_tags([labels_to_tags[y]])for y in Y_pred_labels]\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# Y_test_labels_splitted = [split_tags([labels_to_tags[y]]) for y in Y_test_labels]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m \n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Verify that each sample appears in the test set exactly once\u001b[39;00m\n\u001b[1;32m     52\u001b[0m test_counts \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mint\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:1133\u001b[0m, in \u001b[0;36margsort\u001b[0;34m(a, axis, kind, order)\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_argsort_dispatcher)\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21margsort\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, kind\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;124;03m    Returns the indices that would sort an array.\u001b[39;00m\n\u001b[1;32m   1029\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \n\u001b[1;32m   1132\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43margsort\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:56\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(obj, method, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m bound \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:45\u001b[0m, in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[1;32m     44\u001b[0m     wrap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m, method)(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wrap:\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, mu\u001b[38;5;241m.\u001b[39mndarray):\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (10, 210) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from itertools import combinations\n",
    "\n",
    "def create_label_combinations(y):\n",
    "    \"\"\"Create a single label for each sample based on its combination of labels.\"\"\"\n",
    "    return [''.join(map(str, row[row != -1])) for row in y]\n",
    "\n",
    "def stratified_multi_label_kfold(X, Y, n_splits=5, random_state=None):\n",
    "    # Create label combinations\n",
    "    y_combinations = create_label_combinations(Y)\n",
    "    \n",
    "    # Use StratifiedKFold on the label combinations\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    for train_index, test_index in skf.split(X, y_combinations):\n",
    "        yield train_index, test_index\n",
    "\n",
    "# Number of folds\n",
    "k = 5\n",
    "\n",
    "# Create the k-fold splits\n",
    "\n",
    "X = vivit.embeddings\n",
    "Y = np.array(Y_prepare)\n",
    "kfold_splits = list(stratified_multi_label_kfold(X, Y, n_splits=k, random_state=seed))\n",
    "\n",
    "# Example of how to use the splits\n",
    "for fold, (train_index, test_index) in enumerate(kfold_splits):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    Y_train, Y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "    print(f\"Fold {fold + 1}:\")\n",
    "    print(f\"  Train set shape: X {X_train.shape}, Y {Y_train.shape}\")\n",
    "    print(f\"  Test set shape:  X {X_test.shape}, Y {Y_test.shape}\")\n",
    "    \n",
    "    model = KNeighborsClassifier(n_neighbors=3)\n",
    "    model.fit(X_train, Y_train)\n",
    "    # Y_pred = np.argsort(model.predict_proba(X_test), axis=1)[:, :5]\n",
    "    probas = model.predict_proba(X_test)\n",
    "    print(probas)\n",
    "    print(np.argsort(probas, axis=1)[:, :5])\n",
    "    # Y_pred_labels = np.argsort(model.predict_proba(X_test), axis=1)[:, :5]\n",
    "    # Y_pred = [split_tags([labels_to_tags[y]])for y in Y_pred_labels]\n",
    "    # Y_test_labels_splitted = [split_tags([labels_to_tags[y]]) for y in Y_test_labels]\n",
    "    # # print(classification_report(Y_test, Y_pred))\n",
    "    # iou = calc_iou(Y_pred, Y_test_labels_splitted)\n",
    "    # iou_total += iou\n",
    "    # print(f\"test len: {len(Y_test_labels_splitted)}, len train: {len(Y_train_labels)}\")\n",
    "\n",
    "# Verify that each sample appears in the test set exactly once\n",
    "test_counts = defaultdict(int)\n",
    "for _, test_index in kfold_splits:\n",
    "    for idx in test_index:\n",
    "        test_counts[idx] += 1\n",
    "\n",
    "assert all(count == 1 for count in test_counts.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "135"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tags_to_labels[\"Образование: Онлайн-образование\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([208, 208, 208, ..., 208, 208, 208])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208,\n",
       "       208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208,\n",
       "       208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208,\n",
       "       208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208,\n",
       "       208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208,\n",
       "       208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208,\n",
       "       208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208,\n",
       "       208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208,\n",
       "       208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208,\n",
       "       208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208,\n",
       "       208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208,\n",
       "       208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208,\n",
       "       208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208,\n",
       "       208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208,\n",
       "       208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208,\n",
       "       208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208, 208,\n",
       "       208, 208])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'tolist'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8859/2525747817.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   6295\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6296\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6297\u001b[0m         ):\n\u001b[1;32m   6298\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6299\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'tolist'"
     ]
    }
   ],
   "source": [
    "# all_labels."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
